{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff15512b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _DATATYPE = _descriptor.EnumDescriptor(\n",
      "C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _TENSORPROTO = _descriptor.Descriptor(\n",
      "C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#core enviroment libraries for RL \n",
    "import gym\n",
    "from gym.spaces import Discrete, MultiDiscrete,Box, Dict, MultiBinary,Tuple\n",
    "\n",
    "#utilities \n",
    "import numpy as np\n",
    "import random\n",
    "#these libraries have to do with the agents \n",
    "import ray\n",
    "from ray.rllib.utils.deprecation import Deprecated\n",
    "from ray.rllib.utils.metrics import (\n",
    "    LAST_TARGET_UPDATE_TS,\n",
    "    NUM_AGENT_STEPS_SAMPLED,\n",
    "    NUM_ENV_STEPS_SAMPLED,\n",
    "    NUM_TARGET_UPDATES,\n",
    "    SYNCH_WORKER_WEIGHTS_TIMER,\n",
    ")\n",
    "from ray.rllib.utils.replay_buffers.utils import sample_min_n_steps_from_buffer\n",
    "from ray.rllib.utils.typing import ResultDict, AlgorithmConfigDict\n",
    "from ray.rllib.utils.deprecation import DEPRECATED_VALUE\n",
    "from ray.rllib.utils.deprecation import deprecation_warning\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "from ray import air, tune\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "#import pathpy as pp\n",
    "\n",
    "from ray.tune import register_env\n",
    "from ray.rllib.algorithms.qmix import QMixConfig\n",
    "from ray.rllib.env.multi_agent_env import ENV_STATE\n",
    "from ray.rllib.examples.env.two_step_game import TwoStepGame\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "from ray.rllib.utils.test_utils import check_learning_achieved\n",
    "\n",
    "import mne# preprocessing and brain importation and utilities library including acessing and preprocessing the EEG data\n",
    "#these libraries have to do with the free energy principle\n",
    "#import pymdp\n",
    "#from pymdp import utils\n",
    "#from pymdp.agent import Agent\n",
    "#from gym.spaces import \n",
    "\n",
    "#optimization of deep learning and RL aspects of algorithm these will allow the algorithm to run faster with less memory \n",
    "#from composer import Trainer\n",
    "#from nebullvm.api.functions import optimize_model \n",
    "from numba import jit\n",
    "\n",
    "\"\"\"\n",
    "dependency network\n",
    "\n",
    "Qmix.py - has qmixpolicy.py as a dependency \n",
    "Qmixpolicy.py has  mixers.py and Model.py dependencies\n",
    "Model.py -base\n",
    "mixers.py -base\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import ivy# library for interoperable across all deep learning frameworks \n",
    "#import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "import torch\n",
    "from laplace import Laplace #for model selection \n",
    "from laplace.baselaplace import FullLaplace\n",
    "from laplace.curvature.backpack import BackPackGGN\n",
    "#from nebulgym.decorators.torch_decorators import accel\n",
    "\n",
    "#from nebulgym.decorators.torch_decorators import accelerate_model, accelerate_dataset\n",
    "\n",
    "#below libraries are core libraries for q-mix Rllib algorithm\n",
    "from ray.rllib.models.modelv2 import ModelV2\n",
    "from ray.rllib.models.preprocessors import get_preprocessor\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "from torch import nn\n",
    "\n",
    "from ray.rllib.policy.torch_policy import TorchPolicy\n",
    "\n",
    "from typing import Optional, Type,  Dict, List, Tuple\n",
    "\n",
    "from ray.rllib.algorithms.simple_q.simple_q import SimpleQ, SimpleQConfig\n",
    "from ray.rllib.algorithms.qmix.qmix_policy import QMixTorchPolicy\n",
    "from ray.rllib.utils.replay_buffers.utils import update_priorities_in_replay_buffer\n",
    "from ray.rllib.execution.rollout_ops import (\n",
    "    synchronous_parallel_sample,\n",
    ")\n",
    "\n",
    "from ray.rllib.execution.train_ops import (\n",
    "    multi_gpu_train_one_step,\n",
    "    train_one_step,\n",
    ")\n",
    "from ray.rllib.policy.policy import Policy\n",
    "from ray.rllib.models.preprocessors import get_preprocessor\n",
    "import tree  # pip install dm_tree\n",
    "\n",
    "from ray.rllib.algorithms.qmix.mixers import VDNMixer, QMixer\n",
    "#from ray.rllib.algorithms.qmix.model import RNNModel, _get_size\n",
    "from ray.rllib.env.multi_agent_env import ENV_STATE\n",
    "from ray.rllib.env.wrappers.group_agents_wrapper import GROUP_REWARDS\n",
    "from ray.rllib.models.catalog import ModelCatalog\n",
    "from ray.rllib.models.modelv2 import _unpack_obs\n",
    "from ray.rllib.models.torch.torch_action_dist import TorchCategorical\n",
    "from ray.rllib.policy.rnn_sequencing import chop_into_sequences\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "from ray.rllib.utils.metrics.learner_info import LEARNER_STATS_KEY\n",
    "from ray.rllib.utils.typing import TensorType\n",
    "\n",
    "from ray.tune.registry import get_trainable_cls\n",
    "#from ray.rllib.examples.env.two_step_game import TwoStepGame\n",
    "\n",
    "import nitime\n",
    "from deeptime.sindy import SINDy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d34c669",
   "metadata": {},
   "source": [
    "The expected free energy is minimized by selecting those observations that cause a large change in beliefs, in contrast to variational free energy that is minimized when observations comply wiht current beliefs\n",
    "\n",
    "This is the difference between optmizing beliefs in relation to data that have already been gathered (VFE) and selecting data that will best optimize beliefs \n",
    "\n",
    "Expected free energy furnishes our prior and is a prerequesite in minimzing variational free energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "854300a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch, nn = try_import_torch()\n",
    "\n",
    "class bmodel(TorchModelV2, nn.Module,ivy.Module):\n",
    "    \"\"\"The default RNN model for QMIX.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):#(self, obs_space, action_space, num_outputs, model_config):\n",
    "        TorchModelV2.__init__(\n",
    "             self, obs_space, action_space, num_outputs, model_config, name#self, obs_space, action_space, num_outputs, model_config\n",
    "        )\n",
    "        nn.Module.__init__(self)\n",
    "        self.obs_size = _get_size(obs_space)\n",
    "        self.rnn_hidden_dim = model_config[\"lstm_cell_size\"]\n",
    "        tfk = tf.keras\n",
    "        tfkl = tf.keras.layers\n",
    "        input_shape=2\n",
    "        tfpl = tfp.layers\n",
    "        tfd = tfp.distributions\n",
    "\n",
    "        tfd = tfp.distributions\n",
    "        encoded_size = 16\n",
    "        \n",
    "        \"\"\"\n",
    "        pseudo code\n",
    "        \n",
    "        assign a prior to be the posterior of the output of previous agent\n",
    "        \n",
    "        if no output of agent is found we have a preset prior\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        prior = tfd.Independent(tfd.Normal(loc=tf.zeros(encoded_size), scale=1),\n",
    "                            reinterpreted_batch_ndims=1)\n",
    "        tfpl = tfp.layers\n",
    "        encoder = tfk.Sequential([\n",
    "            tfkl.InputLayer(input_shape=input_shape),\n",
    "            #tfkl.Dense(8)\n",
    "            tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size),\n",
    "                          activation=None),\n",
    "\n",
    "            tfpl.MultivariateNormalTriL(\n",
    "                    encoded_size,\n",
    "                    activity_regularizer=tfpl.KLDivergenceRegularizer(prior, weight=1.2)),\n",
    "        ])\n",
    "        decoder = tfk.Sequential([\n",
    "            tfkl.InputLayer(input_shape=[encoded_size]),\n",
    "            tfkl.Dense(tfpl.IndependentNormal.params_size(encoded_size))\n",
    "            #tfpl.IndependentBernoulli(input_shape, tfd.Bernoulli.logits)\n",
    "\n",
    "        ])\n",
    "        self.fc1 = nn.Linear(self.obs_size, self.rnn_hidden_dim)\n",
    "        self.rnn = nn.GRUCell(self.rnn_hidden_dim, self.rnn_hidden_dim)\n",
    "        self.fc2 = nn.Linear(self.rnn_hidden_dim, num_outputs)\n",
    "        self.n_agents = model_config[\"n_agents\"]\n",
    "\n",
    "    @override(ModelV2)\n",
    "    def get_initial_state(self):\n",
    "\n",
    "        return [\n",
    "            self.fc1.weight.new(self.n_agents, self.rnn_hidden_dim).zero_().squeeze(0)\n",
    "        ]\n",
    "\n",
    "    @override(ModelV2)\n",
    "    def forward(self,x,input_dict, hidden_state, seq_lens):\n",
    "\n",
    "        #negative_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x)\n",
    "                # Place hidden states on same device as model.\n",
    "        \n",
    "        x = nn.functional.relu(self.fc1(input_dict[\"obs_flat\"].float()))\n",
    "        h_in = hidden_state[0].reshape(-1, self.rnn_hidden_dim)\n",
    "        h = self.rnn(x, h_in)\n",
    "        #q = self.fc2(h)\n",
    "        vae = tfk.Model(inputs=input_dict[\"obs_flat\"],\n",
    "                outputs=decoder(input_dict[\"obs_flat\"][0]))\n",
    "        return q, [h]\n",
    "\n",
    "def _get_size(obs_space):\n",
    "    return get_preprocessor(obs_space)(obs_space).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c50b848",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pyro' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\subar\\AppData\\Local\\Temp\\ipykernel_30616\\1083113738.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    guide = pyro.infer.autoguide.AutoNormal(model)\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m\u001b[1;31m:\u001b[0m name 'pyro' is not defined\n"
     ]
    }
   ],
   "source": [
    "guide = pyro.infer.autoguide.AutoNormal(model)\n",
    "\n",
    "elbo = elbo_(model, guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c64c2855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.utils.framework import try_import_torch\n",
    "\n",
    "torch, nn = try_import_torch()\n",
    "\n",
    "class VDNMixer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VDNMixer, self).__init__()\n",
    "\n",
    "    def forward(self, agent_qs, batch):\n",
    "        return torch.sum(agent_qs, dim=2, keepdim=True)\n",
    "\n",
    "\n",
    "class QMixer(nn.Module):\n",
    "    def __init__(self, n_agents, state_shape, mixing_embed_dim):\n",
    "        super(QMixer, self).__init__()\n",
    "\n",
    "        self.n_agents = n_agents\n",
    "        self.embed_dim = mixing_embed_dim\n",
    "        self.state_dim = int(np.prod(state_shape))\n",
    "\n",
    "        self.hyper_w_1 = nn.Linear(self.state_dim, self.embed_dim * self.n_agents)\n",
    "        self.hyper_w_final = nn.Linear(self.state_dim, self.embed_dim)\n",
    "\n",
    "        # State dependent bias for hidden layer\n",
    "        self.hyper_b_1 = nn.Linear(self.state_dim, self.embed_dim)\n",
    "\n",
    "        # V(s) instead of a bias for the last layers\n",
    "        self.V = nn.Sequential(\n",
    "            nn.Linear(self.state_dim, self.embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.embed_dim, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, agent_qs, states):\n",
    "        \"\"\"Forward pass for the mixer.\n",
    "        Args:\n",
    "            agent_qs: Tensor of shape [B, T, n_agents, n_actions]\n",
    "            states: Tensor of shape [B, T, state_dim]\n",
    "        \"\"\"\n",
    "        bs = agent_qs.size(0)\n",
    "        states = states.reshape(-1, self.state_dim)\n",
    "        agent_qs = agent_qs.view(-1, 1, self.n_agents)\n",
    "        # First layer\n",
    "        w1 = torch.abs(self.hyper_w_1(states))\n",
    "        b1 = self.hyper_b_1(states)\n",
    "        w1 = w1.view(-1, self.n_agents, self.embed_dim)\n",
    "        b1 = b1.view(-1, 1, self.embed_dim)\n",
    "        hidden = nn.functional.elu(torch.bmm(agent_qs, w1) + b1)\n",
    "        # Second layer\n",
    "        w_final = torch.abs(self.hyper_w_final(states))\n",
    "        w_final = w_final.view(-1, self.embed_dim, 1)\n",
    "        # State-dependent bias\n",
    "        v = self.V(states).view(-1, 1, 1)\n",
    "        # Compute final output\n",
    "        y = torch.bmm(hidden, w_final) + v\n",
    "        # Reshape and return\n",
    "        q_tot = y.view(bs, -1, 1)\n",
    "        return q_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ebe1537",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QMixLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        target_model,\n",
    "        mixer,\n",
    "        target_mixer,\n",
    "        n_agents,\n",
    "        n_actions,\n",
    "        double_q=True,\n",
    "        gamma=0.99,\n",
    "    ):\n",
    "        nn.Module.__init__(self)\n",
    "        self.model = model\n",
    "        self.target_model = target_model\n",
    "        self.mixer = mixer\n",
    "        self.target_mixer = target_mixer\n",
    "        self.n_agents = n_agents\n",
    "        self.n_actions = n_actions\n",
    "        self.double_q = double_q\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        rewards,\n",
    "        actions,\n",
    "        terminated,\n",
    "        mask,\n",
    "        obs,\n",
    "        next_obs,\n",
    "        action_mask,\n",
    "        next_action_mask,\n",
    "        state=None,\n",
    "        next_state=None,\n",
    "    ):\n",
    "        \"\"\"Forward pass of the loss.\n",
    "        Args:\n",
    "            rewards: Tensor of shape [B, T, n_agents]\n",
    "            actions: Tensor of shape [B, T, n_agents]\n",
    "            terminated: Tensor of shape [B, T, n_agents]\n",
    "            mask: Tensor of shape [B, T, n_agents]\n",
    "            obs: Tensor of shape [B, T, n_agents, obs_size]\n",
    "            next_obs: Tensor of shape [B, T, n_agents, obs_size]\n",
    "            action_mask: Tensor of shape [B, T, n_agents, n_actions]\n",
    "            next_action_mask: Tensor of shape [B, T, n_agents, n_actions]\n",
    "            state: Tensor of shape [B, T, state_dim] (optional)\n",
    "            next_state: Tensor of shape [B, T, state_dim] (optional)\n",
    "        \"\"\"\n",
    "\n",
    "        # Assert either none or both of state and next_state are given\n",
    "        if state is None and next_state is None:\n",
    "            state = obs  # default to state being all agents' observations\n",
    "            next_state = next_obs\n",
    "        elif (state is None) != (next_state is None):\n",
    "            raise ValueError(\n",
    "                \"Expected either neither or both of `state` and \"\n",
    "                \"`next_state` to be given. Got: \"\n",
    "                \"\\n`state` = {}\\n`next_state` = {}\".format(state, next_state)\n",
    "            )\n",
    "\n",
    "        # Calculate estimated Q-Values\n",
    "        mac_out = _unroll_mac(self.model, obs)\n",
    "\n",
    "        # Pick the Q-Values for the actions taken -> [B * n_agents, T]\n",
    "        chosen_action_qvals = torch.gather(\n",
    "            mac_out, dim=3, index=actions.unsqueeze(3)\n",
    "        ).squeeze(3)\n",
    "\n",
    "        # Calculate the Q-Values necessary for the target\n",
    "        target_mac_out = _unroll_mac(self.target_model, next_obs)\n",
    "\n",
    "        # Mask out unavailable actions for the t+1 step\n",
    "        ignore_action_tp1 = (next_action_mask == 0) & (mask == 1).unsqueeze(-1)\n",
    "        target_mac_out[ignore_action_tp1] = -np.inf\n",
    "\n",
    "        # Max over target Q-Values\n",
    "        if self.double_q:\n",
    "            # Double Q learning computes the target Q values by selecting the\n",
    "            # t+1 timestep action according to the \"policy\" neural network and\n",
    "            # then estimating the Q-value of that action with the \"target\"\n",
    "            # neural network\n",
    "\n",
    "            # Compute the t+1 Q-values to be used in action selection\n",
    "            # using next_obs\n",
    "            mac_out_tp1 = _unroll_mac(self.model, next_obs)\n",
    "\n",
    "            # mask out unallowed actions\n",
    "            mac_out_tp1[ignore_action_tp1] = -np.inf\n",
    "\n",
    "            # obtain best actions at t+1 according to policy NN\n",
    "            cur_max_actions = mac_out_tp1.argmax(dim=3, keepdim=True)\n",
    "\n",
    "            # use the target network to estimate the Q-values of policy\n",
    "            # network's selected actions\n",
    "            target_max_qvals = torch.gather(target_mac_out, 3, cur_max_actions).squeeze(\n",
    "                3\n",
    "            )\n",
    "        else:\n",
    "            target_max_qvals = target_mac_out.max(dim=3)[0]\n",
    "\n",
    "        assert (\n",
    "            target_max_qvals.min().item() != -np.inf\n",
    "        ), \"target_max_qvals contains a masked action; \\\n",
    "            there may be a state with no valid actions.\"\n",
    "\n",
    "        # Mix\n",
    "        if self.mixer is not None:\n",
    "            chosen_action_qvals = self.mixer(chosen_action_qvals, state)\n",
    "            target_max_qvals = self.target_mixer(target_max_qvals, next_state)\n",
    "\n",
    "        # Calculate 1-step Q-Learning targets\n",
    "        targets = rewards + self.gamma * (1 - terminated) * target_max_qvals\n",
    "\n",
    "        # Td-error\n",
    "        td_error = chosen_action_qvals - targets.detach()\n",
    "\n",
    "        mask = mask.expand_as(td_error)\n",
    "\n",
    "        # 0-out the targets that came from padded data\n",
    "        masked_td_error = td_error * mask\n",
    "\n",
    "        # Normal L2 loss, take mean over actual data\n",
    "        loss = (masked_td_error**2).sum() / mask.sum()\n",
    "        return loss, mask, masked_td_error, chosen_action_qvals, targets\n",
    "\n",
    "\n",
    "class QMixTorchPolicy(TorchPolicy):\n",
    "    \"\"\"QMix impl. Assumes homogeneous agents for now.\n",
    "    You must use MultiAgentEnv.with_agent_groups() to group agents\n",
    "    together for QMix. This creates the proper Tuple obs/action spaces and\n",
    "    populates the '_group_rewards' info field.\n",
    "    Action masking: to specify an action mask for individual agents, use a\n",
    "    dict space with an action_mask key, e.g. {\"obs\": ob, \"action_mask\": mask}.\n",
    "    The mask space must be `Box(0, 1, (n_actions,))`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, obs_space, action_space, config):\n",
    "        # We want to error out on instantiation and not on import, because tune\n",
    "        # imports all RLlib algorithms when registering them\n",
    "        # TODO (Artur): Find a way to only import algorithms when needed\n",
    "        if not torch:\n",
    "            raise ImportError(\"Could not import PyTorch, which QMix requires.\")\n",
    "\n",
    "        _validate(obs_space, action_space)\n",
    "        config = dict(ray.rllib.algorithms.qmix.qmix.DEFAULT_CONFIG, **config)\n",
    "        self.framework = \"torch\"\n",
    "\n",
    "        self.n_agents = len(obs_space.original_space.spaces)\n",
    "        config[\"model\"][\"n_agents\"] = self.n_agents\n",
    "        self.n_actions = action_space.spaces[0].n\n",
    "        self.h_size = config[\"model\"][\"lstm_cell_size\"]\n",
    "        self.has_env_global_state = False\n",
    "        self.has_action_mask = False\n",
    "\n",
    "        agent_obs_space = obs_space.original_space.spaces[0]\n",
    "        if isinstance(agent_obs_space, gym.spaces.Dict):\n",
    "            space_keys = set(agent_obs_space.spaces.keys())\n",
    "            if \"obs\" not in space_keys:\n",
    "                raise ValueError(\"Dict obs space must have subspace labeled `obs`\")\n",
    "            self.obs_size = _get_size(agent_obs_space.spaces[\"obs\"])\n",
    "            if \"action_mask\" in space_keys:\n",
    "                mask_shape = tuple(agent_obs_space.spaces[\"action_mask\"].shape)\n",
    "                if mask_shape != (self.n_actions,):\n",
    "                    raise ValueError(\n",
    "                        \"Action mask shape must be {}, got {}\".format(\n",
    "                            (self.n_actions,), mask_shape\n",
    "                        )\n",
    "                    )\n",
    "                self.has_action_mask = True\n",
    "            if ENV_STATE in space_keys:\n",
    "                self.env_global_state_shape = _get_size(\n",
    "                    agent_obs_space.spaces[ENV_STATE]\n",
    "                )\n",
    "                self.has_env_global_state = True\n",
    "            else:\n",
    "                self.env_global_state_shape = (self.obs_size, self.n_agents)\n",
    "            # The real agent obs space is nested inside the dict\n",
    "            config[\"model\"][\"full_obs_space\"] = agent_obs_space\n",
    "            agent_obs_space = agent_obs_space.spaces[\"obs\"]\n",
    "        else:\n",
    "            self.obs_size = _get_size(agent_obs_space)\n",
    "            self.env_global_state_shape = (self.obs_size, self.n_agents)\n",
    "        #model = bmodel()#CModel()#CModel()\n",
    "        #bmodel = Laplace(model,'regression', subset_of_weights='last_layer', hessian_structure='full')#\n",
    "        ivy.set_framework('torch')\n",
    "        #model = Laplace(model,'regression', subset_of_weights='last_layer', hessian_structure='full')\n",
    "        bmodel = bmodel()\n",
    "        bmodel = FullLaplace(bmodel,'regression',prior_precision=2)\n",
    "        self.model = ModelCatalog.get_model_v2(\n",
    "            agent_obs_space,\n",
    "            action_space.spaces[0],\n",
    "            self.n_actions,\n",
    "            config[\"model\"],\n",
    "            framework=\"torch\",\n",
    "            name=\"model\",\n",
    "            default_model=bmodel#a#RNNModel#bmodel()#RNNModel,\n",
    "        )\n",
    "\n",
    "        super().__init__(obs_space, action_space, config, model=self.model)\n",
    "\n",
    "        self.target_model = ModelCatalog.get_model_v2(\n",
    "            agent_obs_space,\n",
    "            action_space.spaces[0],\n",
    "            self.n_actions,\n",
    "            config[\"model\"],\n",
    "            framework=\"torch\",\n",
    "            name=\"target_model\",\n",
    "            default_model=bmodel#bmodel()#RNNModel\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.exploration = self._create_exploration()\n",
    "\n",
    "        # Setup the mixer network.\n",
    "        if config[\"mixer\"] is None:\n",
    "            self.mixer = None\n",
    "            self.target_mixer = None\n",
    "        elif config[\"mixer\"] == \"qmix\":\n",
    "            self.mixer = QMixer(\n",
    "                self.n_agents, self.env_global_state_shape, config[\"mixing_embed_dim\"]\n",
    "            ).to(self.device)\n",
    "            self.target_mixer = QMixer(\n",
    "                self.n_agents, self.env_global_state_shape, config[\"mixing_embed_dim\"]\n",
    "            ).to(self.device)\n",
    "        elif config[\"mixer\"] == \"vdn\":\n",
    "            self.mixer = VDNMixer().to(self.device)\n",
    "            self.target_mixer = VDNMixer().to(self.device)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown mixer type {}\".format(config[\"mixer\"]))\n",
    "\n",
    "        self.cur_epsilon = 1.0\n",
    "        self.update_target()  # initial sync\n",
    "\n",
    "        # Setup optimizer\n",
    "        self.params = list(self.model.parameters())\n",
    "        if self.mixer:\n",
    "            self.params += list(self.mixer.parameters())\n",
    "        self.loss = QMixLoss(\n",
    "            self.model,\n",
    "            self.target_model,\n",
    "            self.mixer,\n",
    "            self.target_mixer,\n",
    "            self.n_agents,\n",
    "            self.n_actions,\n",
    "            self.config[\"double_q\"],\n",
    "            self.config[\"gamma\"],\n",
    "        )\n",
    "        from torch.optim import RMSprop\n",
    "\n",
    "        self.rmsprop_optimizer = RMSprop(\n",
    "            params=self.params,\n",
    "            lr=config[\"lr\"],\n",
    "            alpha=config[\"optim_alpha\"],\n",
    "            eps=config[\"optim_eps\"],\n",
    "        )\n",
    "\n",
    "    @override(TorchPolicy)\n",
    "    def compute_actions_from_input_dict(\n",
    "        self,\n",
    "        input_dict: Dict[str, TensorType],\n",
    "        explore: bool = None,\n",
    "        timestep: Optional[int] = None,\n",
    "        **kwargs,\n",
    "    ) -> Tuple[TensorType, List[TensorType], Dict[str, TensorType]]:\n",
    "\n",
    "        obs_batch = input_dict[SampleBatch.OBS]\n",
    "        state_batches = []\n",
    "        i = 0\n",
    "        while f\"state_in_{i}\" in input_dict:\n",
    "            state_batches.append(input_dict[f\"state_in_{i}\"])\n",
    "            i += 1\n",
    "\n",
    "        explore = explore if explore is not None else self.config[\"explore\"]\n",
    "        obs_batch, action_mask, _ = self._unpack_observation(obs_batch)\n",
    "        # We need to ensure we do not use the env global state\n",
    "        # to compute actions\n",
    "\n",
    "        # Compute actions\n",
    "        with torch.no_grad():\n",
    "            q_values, hiddens = _mac(\n",
    "                self.model,\n",
    "                torch.as_tensor(obs_batch, dtype=torch.float, device=self.device),\n",
    "                [\n",
    "                    torch.as_tensor(np.array(s), dtype=torch.float, device=self.device)\n",
    "                    for s in state_batches\n",
    "                ],\n",
    "            )\n",
    "            avail = torch.as_tensor(action_mask, dtype=torch.float, device=self.device)\n",
    "            masked_q_values = q_values.clone()\n",
    "            masked_q_values[avail == 0.0] = -float(\"inf\")\n",
    "            masked_q_values_folded = torch.reshape(\n",
    "                masked_q_values, [-1] + list(masked_q_values.shape)[2:]\n",
    "            )\n",
    "            actions, _ = self.exploration.get_exploration_action(\n",
    "                action_distribution=TorchCategorical(masked_q_values_folded),\n",
    "                timestep=timestep,\n",
    "                explore=explore,\n",
    "            )\n",
    "            actions = (\n",
    "                torch.reshape(actions, list(masked_q_values.shape)[:-1]).cpu().numpy()\n",
    "            )\n",
    "            hiddens = [s.cpu().numpy() for s in hiddens]\n",
    "\n",
    "        return tuple(actions.transpose([1, 0])), hiddens, {}\n",
    "\n",
    "    @override(TorchPolicy)\n",
    "    def compute_actions(self, *args, **kwargs):\n",
    "        return self.compute_actions_from_input_dict(*args, **kwargs)\n",
    "\n",
    "    @override(TorchPolicy)\n",
    "    def compute_log_likelihoods(\n",
    "        self,\n",
    "        actions,\n",
    "        obs_batch,\n",
    "        state_batches=None,\n",
    "        prev_action_batch=None,\n",
    "        prev_reward_batch=None,\n",
    "    ):\n",
    "        obs_batch, action_mask, _ = self._unpack_observation(obs_batch)\n",
    "        return np.zeros(obs_batch.size()[0])\n",
    "\n",
    "    @override(TorchPolicy)\n",
    "    def learn_on_batch(self, samples):\n",
    "        obs_batch, action_mask, env_global_state = self._unpack_observation(\n",
    "            samples[SampleBatch.CUR_OBS]\n",
    "        )\n",
    "        (\n",
    "            next_obs_batch,\n",
    "            next_action_mask,\n",
    "            next_env_global_state,\n",
    "        ) = self._unpack_observation(samples[SampleBatch.NEXT_OBS])\n",
    "        group_rewards = self._get_group_rewards(samples[SampleBatch.INFOS])\n",
    "\n",
    "        input_list = [\n",
    "            group_rewards,\n",
    "            action_mask,\n",
    "            next_action_mask,\n",
    "            samples[SampleBatch.ACTIONS],\n",
    "            samples[SampleBatch.TERMINATEDS],\n",
    "            obs_batch,\n",
    "            next_obs_batch,\n",
    "        ]\n",
    "        if self.has_env_global_state:\n",
    "            input_list.extend([env_global_state, next_env_global_state])\n",
    "\n",
    "        output_list, _, seq_lens = chop_into_sequences(\n",
    "            episode_ids=samples[SampleBatch.EPS_ID],\n",
    "            unroll_ids=samples[SampleBatch.UNROLL_ID],\n",
    "            agent_indices=samples[SampleBatch.AGENT_INDEX],\n",
    "            feature_columns=input_list,\n",
    "            state_columns=[],  # RNN states not used here\n",
    "            max_seq_len=self.config[\"model\"][\"max_seq_len\"],\n",
    "            dynamic_max=True,\n",
    "        )\n",
    "        # These will be padded to shape [B * T, ...]\n",
    "        if self.has_env_global_state:\n",
    "            (\n",
    "                rew,\n",
    "                action_mask,\n",
    "                next_action_mask,\n",
    "                act,\n",
    "                terminateds,\n",
    "                obs,\n",
    "                next_obs,\n",
    "                env_global_state,\n",
    "                next_env_global_state,\n",
    "            ) = output_list\n",
    "        else:\n",
    "            (\n",
    "                rew,\n",
    "                action_mask,\n",
    "                next_action_mask,\n",
    "                act,\n",
    "                terminateds,\n",
    "                obs,\n",
    "                next_obs,\n",
    "            ) = output_list\n",
    "        B, T = len(seq_lens), max(seq_lens)\n",
    "\n",
    "        def to_batches(arr, dtype):\n",
    "            new_shape = [B, T] + list(arr.shape[1:])\n",
    "            return torch.as_tensor(\n",
    "                np.reshape(arr, new_shape), dtype=dtype, device=self.device\n",
    "            )\n",
    "\n",
    "        rewards = to_batches(rew, torch.float)\n",
    "        actions = to_batches(act, torch.long)\n",
    "        obs = to_batches(obs, torch.float).reshape([B, T, self.n_agents, self.obs_size])\n",
    "        action_mask = to_batches(action_mask, torch.float)\n",
    "        next_obs = to_batches(next_obs, torch.float).reshape(\n",
    "            [B, T, self.n_agents, self.obs_size]\n",
    "        )\n",
    "        next_action_mask = to_batches(next_action_mask, torch.float)\n",
    "        if self.has_env_global_state:\n",
    "            env_global_state = to_batches(env_global_state, torch.float)\n",
    "            next_env_global_state = to_batches(next_env_global_state, torch.float)\n",
    "\n",
    "        # TODO(ekl) this treats group termination as individual termination\n",
    "        terminated = (\n",
    "            to_batches(terminateds, torch.float)\n",
    "            .unsqueeze(2)\n",
    "            .expand(B, T, self.n_agents)\n",
    "        )\n",
    "\n",
    "        # Create mask for where index is < unpadded sequence length\n",
    "        filled = np.reshape(\n",
    "            np.tile(np.arange(T, dtype=np.float32), B), [B, T]\n",
    "        ) < np.expand_dims(seq_lens, 1)\n",
    "        mask = (\n",
    "            torch.as_tensor(filled, dtype=torch.float, device=self.device)\n",
    "            .unsqueeze(2)\n",
    "            .expand(B, T, self.n_agents)\n",
    "        )\n",
    "\n",
    "        # Compute loss\n",
    "        loss_out, mask, masked_td_error, chosen_action_qvals, targets = self.loss(\n",
    "            rewards,\n",
    "            actions,\n",
    "            terminated,\n",
    "            mask,\n",
    "            obs,\n",
    "            next_obs,\n",
    "            action_mask,\n",
    "            next_action_mask,\n",
    "            env_global_state,\n",
    "            next_env_global_state,\n",
    "        )\n",
    "\n",
    "        # Optimise\n",
    "        self.rmsprop_optimizer.zero_grad()\n",
    "        loss_out.backward()\n",
    "        grad_norm_info = apply_grad_clipping(self, self.rmsprop_optimizer, loss_out)\n",
    "        self.rmsprop_optimizer.step()\n",
    "\n",
    "        mask_elems = mask.sum().item()\n",
    "        stats = {\n",
    "            \"loss\": loss_out.item(),\n",
    "            \"td_error_abs\": masked_td_error.abs().sum().item() / mask_elems,\n",
    "            \"q_taken_mean\": (chosen_action_qvals * mask).sum().item() / mask_elems,\n",
    "            \"target_mean\": (targets * mask).sum().item() / mask_elems,\n",
    "        }\n",
    "        stats.update(grad_norm_info)\n",
    "\n",
    "        return {LEARNER_STATS_KEY: stats}\n",
    "\n",
    "    @override(TorchPolicy)\n",
    "    def get_initial_state(self):  # initial RNN state\n",
    "        return [\n",
    "            s.expand([self.n_agents, -1]).cpu().numpy()\n",
    "            for s in self.model.get_initial_state()\n",
    "        ]\n",
    "\n",
    "    @override(TorchPolicy)\n",
    "    def get_weights(self):\n",
    "        return {\n",
    "            \"model\": self._cpu_dict(self.model.state_dict()),\n",
    "            \"target_model\": self._cpu_dict(self.target_model.state_dict()),\n",
    "            \"mixer\": self._cpu_dict(self.mixer.state_dict()) if self.mixer else None,\n",
    "            \"target_mixer\": self._cpu_dict(self.target_mixer.state_dict())\n",
    "            if self.mixer\n",
    "            else None,\n",
    "        }\n",
    "\n",
    "    @override(TorchPolicy)\n",
    "    def set_weights(self, weights):\n",
    "        self.model.load_state_dict(self._device_dict(weights[\"model\"]))\n",
    "        self.target_model.load_state_dict(self._device_dict(weights[\"target_model\"]))\n",
    "        if weights[\"mixer\"] is not None:\n",
    "            self.mixer.load_state_dict(self._device_dict(weights[\"mixer\"]))\n",
    "            self.target_mixer.load_state_dict(\n",
    "                self._device_dict(weights[\"target_mixer\"])\n",
    "            )\n",
    "\n",
    "    @override(TorchPolicy)\n",
    "    def get_state(self):\n",
    "        state = self.get_weights()\n",
    "        state[\"cur_epsilon\"] = self.cur_epsilon\n",
    "        return state\n",
    "\n",
    "    @override(TorchPolicy)\n",
    "    def set_state(self, state):\n",
    "        self.set_weights(state)\n",
    "        self.set_epsilon(state[\"cur_epsilon\"])\n",
    "\n",
    "    def update_target(self):\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "        if self.mixer is not None:\n",
    "            self.target_mixer.load_state_dict(self.mixer.state_dict())\n",
    "        logger.debug(\"Updated target networks\")\n",
    "\n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.cur_epsilon = epsilon\n",
    "\n",
    "    def _get_group_rewards(self, info_batch):\n",
    "        group_rewards = np.array(\n",
    "            [info.get(GROUP_REWARDS, [0.0] * self.n_agents) for info in info_batch]\n",
    "        )\n",
    "        return group_rewards\n",
    "\n",
    "    def _device_dict(self, state_dict):\n",
    "        return {\n",
    "            k: torch.as_tensor(v, device=self.device) for k, v in state_dict.items()\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def _cpu_dict(state_dict):\n",
    "        return {k: v.cpu().detach().numpy() for k, v in state_dict.items()}\n",
    "\n",
    "    def _unpack_observation(self, obs_batch):\n",
    "        \"\"\"Unpacks the observation, action mask, and state (if present)\n",
    "        from agent grouping.\n",
    "        Returns:\n",
    "            obs (np.ndarray): obs tensor of shape [B, n_agents, obs_size]\n",
    "            mask (np.ndarray): action mask, if any\n",
    "            state (np.ndarray or None): state tensor of shape [B, state_size]\n",
    "                or None if it is not in the batch\n",
    "        \"\"\"\n",
    "\n",
    "        unpacked = _unpack_obs(\n",
    "            np.array(obs_batch, dtype=np.float32),\n",
    "            self.observation_space.original_space,\n",
    "            tensorlib=np,\n",
    "        )\n",
    "\n",
    "        if isinstance(unpacked[0], dict):\n",
    "            assert \"obs\" in unpacked[0]\n",
    "            unpacked_obs = [np.concatenate(tree.flatten(u[\"obs\"]), 1) for u in unpacked]\n",
    "        else:\n",
    "            unpacked_obs = unpacked\n",
    "\n",
    "        obs = np.concatenate(unpacked_obs, axis=1).reshape(\n",
    "            [len(obs_batch), self.n_agents, self.obs_size]\n",
    "        )\n",
    "\n",
    "        if self.has_action_mask:\n",
    "            action_mask = np.concatenate(\n",
    "                [o[\"action_mask\"] for o in unpacked], axis=1\n",
    "            ).reshape([len(obs_batch), self.n_agents, self.n_actions])\n",
    "        else:\n",
    "            action_mask = np.ones(\n",
    "                [len(obs_batch), self.n_agents, self.n_actions], dtype=np.float32\n",
    "            )\n",
    "\n",
    "        if self.has_env_global_state:\n",
    "            state = np.concatenate(tree.flatten(unpacked[0][ENV_STATE]), 1)\n",
    "        else:\n",
    "            state = None\n",
    "        return obs, action_mask, state\n",
    "\n",
    "\n",
    "def _validate(obs_space, action_space):\n",
    "    if not hasattr(obs_space, \"original_space\") or not isinstance(\n",
    "        obs_space.original_space, gym.spaces.Tuple\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"Obs space must be a Tuple, got {}. Use \".format(obs_space)\n",
    "            + \"MultiAgentEnv.with_agent_groups() to group related \"\n",
    "            \"agents for QMix.\"\n",
    "        )\n",
    "    if not isinstance(action_space, gym.spaces.Tuple):\n",
    "        raise ValueError(\n",
    "            \"Action space must be a Tuple, got {}. \".format(action_space)\n",
    "            + \"Use MultiAgentEnv.with_agent_groups() to group related \"\n",
    "            \"agents for QMix.\"\n",
    "        )\n",
    "    if not isinstance(action_space.spaces[0], gym.spaces.Discrete):\n",
    "        raise ValueError(\n",
    "            \"QMix requires a discrete action space, got {}\".format(\n",
    "                action_space.spaces[0]\n",
    "            )\n",
    "        )\n",
    "    if len({str(x) for x in obs_space.original_space.spaces}) > 1:\n",
    "        raise ValueError(\n",
    "            \"Implementation limitation: observations of grouped agents \"\n",
    "            \"must be homogeneous, got {}\".format(obs_space.original_space.spaces)\n",
    "        )\n",
    "    if len({str(x) for x in action_space.spaces}) > 1:\n",
    "        raise ValueError(\n",
    "            \"Implementation limitation: action space of grouped agents \"\n",
    "            \"must be homogeneous, got {}\".format(action_space.spaces)\n",
    "        )\n",
    "\n",
    "\n",
    "def _mac(model, obs, h):\n",
    "    \"\"\"Forward pass of the multi-agent controller.\n",
    "    Args:\n",
    "        model: TorchModelV2 class\n",
    "        obs: Tensor of shape [B, n_agents, obs_size]\n",
    "        h: List of tensors of shape [B, n_agents, h_size]\n",
    "    Returns:\n",
    "        q_vals: Tensor of shape [B, n_agents, n_actions]\n",
    "        h: Tensor of shape [B, n_agents, h_size]\n",
    "    \"\"\"\n",
    "    B, n_agents = obs.size(0), obs.size(1)\n",
    "    if not isinstance(obs, dict):\n",
    "        obs = {\"obs\": obs}\n",
    "    obs_agents_as_batches = {k: _drop_agent_dim(v) for k, v in obs.items()}\n",
    "    h_flat = [s.reshape([B * n_agents, -1]) for s in h]\n",
    "    q_flat, h_flat = model(obs_agents_as_batches, h_flat, None)\n",
    "    return q_flat.reshape([B, n_agents, -1]), [\n",
    "        s.reshape([B, n_agents, -1]) for s in h_flat\n",
    "    ]\n",
    "\n",
    "def _unroll_mac(model, obs_tensor):\n",
    "    \"\"\"Computes the estimated Q values for an entire trajectory batch\"\"\"\n",
    "    B = obs_tensor.size(0)\n",
    "    T = obs_tensor.size(1)\n",
    "    n_agents = obs_tensor.size(2)\n",
    "\n",
    "    mac_out = []\n",
    "    h = [s.expand([B, n_agents, -1]) for s in model.get_initial_state()]\n",
    "    for t in range(T):\n",
    "        q, h = _mac(model, obs_tensor[:, t], h)\n",
    "        mac_out.append(q)\n",
    "    mac_out = torch.stack(mac_out, dim=1)  # Concat over time\n",
    "\n",
    "    return mac_out\n",
    "\n",
    "def _drop_agent_dim(T):\n",
    "    shape = list(T.shape)\n",
    "    B, n_agents = shape[0], shape[1]\n",
    "    return T.reshape([B * n_agents] + shape[2:])\n",
    "\n",
    "def _add_agent_dim(T, n_agents):\n",
    "    shape = list(T.shape)\n",
    "    B = shape[0] // n_agents\n",
    "    assert shape[0] % n_agents == 0\n",
    "    return T.reshape([B, n_agents] + shape[1:])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d5b1bb6",
   "metadata": {},
   "source": [
    "psuedo code for assigning prior\n",
    "\n",
    "if agent_id.startswith(\"high_level_\"):\n",
    "    assign non informative prior\n",
    "else:\n",
    "    prior = posterior\n",
    "\n",
    "\n",
    "our 3 kinds of agents will be \n",
    "\n",
    "excitatory, inhibitory and motor\n",
    "\n",
    "two kinds of priors: priors about states or precisions or structural priors about generative model\n",
    "\n",
    "policy priors depend on expected free energy which itself depends on posterior beliefs, the potential for information gain and prior preferences\n",
    "\n",
    "priors over policies can also be equipped with a fixed form term representing habitual biases \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3523b705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass TwoStepGameWithGroupedAgents(MultiAgentEnv):\\n    def __init__(self, env_config):\\n        super().__init__()\\n        env = TwoStepGame(env_config)\\n        tuple_obs_space = Tuple([env.observation_space, env.observation_space])\\n        tuple_act_space = Tuple([env.action_space, env.action_space])\\n\\n        self.env = env.with_agent_groups(\\n            groups={\"agents\": [0, 1]},\\n            obs_space=tuple_obs_space,\\n            act_space=tuple_act_space,\\n        )\\n        self.observation_space = self.env.observation_space\\n        self.action_space = self.env.action_space\\n        self._agent_ids = {\"agents\"}\\n\\n    def reset(self, *, seed=None, options=None):\\n        return self.env.reset(seed=seed, options=options)\\n\\n    def step(self, actions):\\n        return self.env.step(actions)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TwoStepGame(MultiAgentEnv):\n",
    "    action_space = Discrete(2)\n",
    "\n",
    "    def __init__(self, env_config):\n",
    "        super().__init__()\n",
    "        self.action_space = Discrete(2)\n",
    "        self.state = None\n",
    "        self.agent_1 = 0\n",
    "        self.agent_2 = 1\n",
    "        #self.agent_3=2\n",
    "        self._skip_env_checking = True\n",
    "        # MADDPG emits action logits instead of actual discrete actions\n",
    "        self.actions_are_logits = env_config.get(\"actions_are_logits\", False)\n",
    "        self.one_hot_state_encoding = env_config.get(\"one_hot_state_encoding\", False)\n",
    "        self.with_state = env_config.get(\"separate_state_space\", False)\n",
    "        self._agent_ids = {0, 1}\n",
    "        if not self.one_hot_state_encoding:\n",
    "            self.observation_space = Discrete(6)\n",
    "            self.with_state = False\n",
    "        else:\n",
    "            # Each agent gets the full state (one-hot encoding of which of the\n",
    "            # three states are active) as input with the receiving agent's\n",
    "            # ID (1 or 2) concatenated onto the end.\n",
    "            if self.with_state:\n",
    "                self.observation_space = Dict(\n",
    "                    {\n",
    "                        \"obs\": MultiDiscrete([2, 2, 2, 3]),\n",
    "                        ENV_STATE: MultiDiscrete([2, 2, 2]),\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                self.observation_space = MultiDiscrete([2, 2, 2, 3])\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        self.state = np.array([1, 0, 0])\n",
    "        return self._obs(), {}\n",
    "\n",
    "    def step(self, action_dict):\n",
    "\n",
    "        state_index = np.flatnonzero(self.state)\n",
    "        if state_index == 0:\n",
    "            action = action_dict[self.agent_1]\n",
    "            assert action in [0, 1], action\n",
    "            if action == 0:\n",
    "                self.state = np.array([0, 1, 0])\n",
    "            else:\n",
    "                self.state = np.array([0, 0, 1])\n",
    "            global_rew = 0\n",
    "            terminated = False\n",
    "        elif state_index == 1:\n",
    "            global_rew = 7\n",
    "            terminated = True\n",
    "        else:\n",
    "            if action_dict[self.agent_1] == 0 and action_dict[self.agent_2] == 0:\n",
    "                global_rew = 0\n",
    "            elif action_dict[self.agent_1] == 1 and action_dict[self.agent_2] == 1:\n",
    "                global_rew = 8\n",
    "            else:\n",
    "                global_rew = 1\n",
    "            terminated = True\n",
    "            \n",
    "        \"\"\"\n",
    "        guide = pyro.infer.autoguide.AutoNormal(model)\n",
    "\n",
    "        elbo = elbo_(model, guide)\n",
    "        \n",
    "        el = elbo(data)\n",
    "        \n",
    "        \n",
    "        #rewards = {self.agent_1:kullbacker, self.agent_2: el}\n",
    "        #loss = lambda y, rv_y: rv_y.variational_loss(y, kl_weight=np.array(batch_size, x.dtype) / x.shape[0])\n",
    "        #kull = tf.keras.losses.KLDivergence()        \n",
    "        \"\"\"\n",
    "\n",
    "        rewards = {self.agent_1: global_rew / 2.0, self.agent_2: global_rew / 2.0}\n",
    "        obs = self._obs()\n",
    "        terminateds = {\"__all__\": terminated}\n",
    "        truncateds = {\"__all__\": False}\n",
    "        infos = {\n",
    "            self.agent_1: {\"done\": terminateds[\"__all__\"]},\n",
    "            self.agent_2: {\"done\": terminateds[\"__all__\"]},\n",
    "        }\n",
    "        return obs, rewards, terminateds, truncateds, infos\n",
    "\n",
    "    def _obs(self):\n",
    "        if self.with_state:\n",
    "            return {\n",
    "                self.agent_1: {\"obs\": self.agent_1_obs(), ENV_STATE: self.state},\n",
    "                self.agent_2: {\"obs\": self.agent_2_obs(), ENV_STATE: self.state},\n",
    "            }\n",
    "        else:\n",
    "            return {self.agent_1: self.agent_1_obs(), self.agent_2: self.agent_2_obs()}\n",
    "\n",
    "    def agent_1_obs(self):\n",
    "        if self.one_hot_state_encoding:\n",
    "            return np.concatenate([self.state, [1]])\n",
    "        else:\n",
    "            return np.flatnonzero(self.state)[0]\n",
    "\n",
    "    def agent_2_obs(self):\n",
    "        if self.one_hot_state_encoding:\n",
    "            return np.concatenate([self.state, [2]])\n",
    "        else:\n",
    "            return np.flatnonzero(self.state)[0] + 3\n",
    "\n",
    "\"\"\"\n",
    "class TwoStepGameWithGroupedAgents(MultiAgentEnv):\n",
    "    def __init__(self, env_config):\n",
    "        super().__init__()\n",
    "        env = TwoStepGame(env_config)\n",
    "        tuple_obs_space = Tuple([env.observation_space, env.observation_space])\n",
    "        tuple_act_space = Tuple([env.action_space, env.action_space])\n",
    "\n",
    "        self.env = env.with_agent_groups(\n",
    "            groups={\"agents\": [0, 1]},\n",
    "            obs_space=tuple_obs_space,\n",
    "            act_space=tuple_act_space,\n",
    "        )\n",
    "        self.observation_space = self.env.observation_space\n",
    "        self.action_space = self.env.action_space\n",
    "        self._agent_ids = {\"agents\"}\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        return self.env.reset(seed=seed, options=options)\n",
    "\n",
    "    def step(self, actions):\n",
    "        return self.env.step(actions)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba14475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a20b99a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type\n",
    "\n",
    "from ray.rllib.algorithms.algorithm_config import AlgorithmConfig, NotProvided\n",
    "from ray.rllib.algorithms.simple_q.simple_q import SimpleQ, SimpleQConfig\n",
    "from ray.rllib.algorithms.qmix.qmix_policy import QMixTorchPolicy\n",
    "from ray.rllib.utils.replay_buffers.utils import update_priorities_in_replay_buffer\n",
    "from ray.rllib.execution.rollout_ops import (\n",
    "    synchronous_parallel_sample,\n",
    ")\n",
    "from ray.rllib.execution.train_ops import (\n",
    "    multi_gpu_train_one_step,\n",
    "    train_one_step,\n",
    ")\n",
    "from ray.rllib.policy.policy import Policy\n",
    "from ray.rllib.utils.annotations import override\n",
    "from ray.rllib.utils.deprecation import Deprecated\n",
    "from ray.rllib.utils.metrics import (\n",
    "    LAST_TARGET_UPDATE_TS,\n",
    "    NUM_AGENT_STEPS_SAMPLED,\n",
    "    NUM_ENV_STEPS_SAMPLED,\n",
    "    NUM_TARGET_UPDATES,\n",
    "    SYNCH_WORKER_WEIGHTS_TIMER,\n",
    "    SAMPLE_TIMER,\n",
    ")\n",
    "from ray.rllib.utils.replay_buffers.utils import sample_min_n_steps_from_buffer\n",
    "from ray.rllib.utils.typing import ResultDict\n",
    "from ray.rllib.utils.deprecation import DEPRECATED_VALUE\n",
    "from ray.rllib.utils.deprecation import deprecation_warning\n",
    "\n",
    "class QMixConfig(SimpleQConfig):\n",
    "    \"\"\"Defines a configuration class from which QMix can be built.\n",
    "    Example:\n",
    "        >>> from ray.rllib.examples.env.two_step_game import TwoStepGame\n",
    "        >>> from ray.rllib.algorithms.qmix import QMixConfig\n",
    "        >>> config = QMixConfig()  # doctest: +SKIP\n",
    "        >>> config = config.training(gamma=0.9, lr=0.01, kl_coeff=0.3)  # doctest: +SKIP\n",
    "        >>> config = config.resources(num_gpus=0)  # doctest: +SKIP\n",
    "        >>> config = config.rollouts(num_rollout_workers=4)  # doctest: +SKIP\n",
    "        >>> print(config.to_dict())  # doctest: +SKIP\n",
    "        >>> # Build an Algorithm object from the config and run 1 training iteration.\n",
    "        >>> algo = config.build(env=TwoStepGame)  # doctest: +SKIP\n",
    "        >>> algo.train()  # doctest: +SKIP\n",
    "    Example:\n",
    "        >>> from ray.rllib.examples.env.two_step_game import TwoStepGame\n",
    "        >>> from ray.rllib.algorithms.qmix import QMixConfig\n",
    "        >>> from ray import air\n",
    "        >>> from ray import tune\n",
    "        >>> config = QMixConfig()\n",
    "        >>> # Print out some default values.\n",
    "        >>> print(config.optim_alpha)  # doctest: +SKIP\n",
    "        >>> # Update the config object.\n",
    "        >>> config.training(  # doctest: +SKIP\n",
    "        ...     lr=tune.grid_search([0.001, 0.0001]), optim_alpha=0.97\n",
    "        ... )\n",
    "        >>> # Set the config object's env.\n",
    "        >>> config.environment(env=TwoStepGame)  # doctest: +SKIP\n",
    "        >>> # Use to_dict() to get the old-style python config dict\n",
    "        >>> # when running with tune.\n",
    "        >>> tune.Tuner(  # doctest: +SKIP\n",
    "        ...     \"QMix\",\n",
    "        ...     run_config=air.RunConfig(stop={\"episode_reward_mean\": 200}),\n",
    "        ...     param_space=config.to_dict(),\n",
    "        ... ).fit()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes a PPOConfig instance.\"\"\"\n",
    "        super().__init__(algo_class=QMix)\n",
    "\n",
    "        # fmt: off\n",
    "        # __sphinx_doc_begin__\n",
    "        # QMix specific settings:\n",
    "        self.mixer = \"qmix\"\n",
    "        self.mixing_embed_dim = 32\n",
    "        self.double_q = True\n",
    "        self.optim_alpha = 0.99\n",
    "        self.optim_eps = 0.00001\n",
    "        self.grad_clip = 10\n",
    "\n",
    "        # QMix-torch overrides the TorchPolicy's learn_on_batch w/o specifying a\n",
    "        # alternative `learn_on_loaded_batch` alternative for the GPU.\n",
    "        # TODO: This hack will be resolved once we move all algorithms to the new\n",
    "        #  RLModule/Learner APIs.\n",
    "        self.simple_optimizer = True\n",
    "\n",
    "        # Override some of AlgorithmConfig's default values with QMix-specific values.\n",
    "        # .training()\n",
    "        self.lr = 0.0005\n",
    "        self.train_batch_size = 32\n",
    "        self.target_network_update_freq = 500\n",
    "        self.num_steps_sampled_before_learning_starts = 1000\n",
    "        self.replay_buffer_config = {\n",
    "            \"type\": \"ReplayBuffer\",\n",
    "            # Specify prioritized replay by supplying a buffer type that supports\n",
    "            # prioritization, for example: MultiAgentPrioritizedReplayBuffer.\n",
    "            \"prioritized_replay\": DEPRECATED_VALUE,\n",
    "            # Size of the replay buffer in batches (not timesteps!).\n",
    "            \"capacity\": 1000,\n",
    "            # Choosing `fragments` here makes it so that the buffer stores entire\n",
    "            # batches, instead of sequences, episodes or timesteps.\n",
    "            \"storage_unit\": \"fragments\",\n",
    "            # Whether to compute priorities on workers.\n",
    "            \"worker_side_prioritization\": False,\n",
    "        }\n",
    "        \"\"\"\n",
    "        self.model = {\n",
    "            \"lstm_cell_size\": 64,\n",
    "            \"max_seq_len\": 999999,\n",
    "        }\n",
    "        \"\"\"\n",
    "        # .framework()\n",
    "        self.framework_str = \"torch\"\n",
    "\n",
    "        # .rollouts()\n",
    "        self.rollout_fragment_length = 4\n",
    "        self.batch_mode = \"complete_episodes\"\n",
    "\n",
    "        # .reporting()\n",
    "        self.min_time_s_per_iteration = 1\n",
    "        self.min_sample_timesteps_per_iteration = 1000\n",
    "\n",
    "        # .exploration()\n",
    "        self.exploration_config = {\n",
    "            # The Exploration class to use.\n",
    "            \"type\": \"EpsilonGreedy\",\n",
    "            # Config for the Exploration class' constructor:\n",
    "            \"initial_epsilon\": 1.0,\n",
    "            \"final_epsilon\": 0.01,\n",
    "            # Timesteps over which to anneal epsilon.\n",
    "            \"epsilon_timesteps\": 40000,\n",
    "\n",
    "            # For soft_q, use:\n",
    "            # \"exploration_config\" = {\n",
    "            #   \"type\": \"SoftQ\"\n",
    "            #   \"temperature\": [float, e.g. 1.0]\n",
    "            # }\n",
    "        }\n",
    "\n",
    "        # .evaluation()\n",
    "        # Evaluate with epsilon=0 every `evaluation_interval` training iterations.\n",
    "        # The evaluation stats will be reported under the \"evaluation\" metric key.\n",
    "        self.evaluation(\n",
    "            evaluation_config=AlgorithmConfig.overrides(explore=False)\n",
    "        )\n",
    "        # __sphinx_doc_end__\n",
    "        # fmt: on\n",
    "\n",
    "        self.worker_side_prioritization = DEPRECATED_VALUE\n",
    "\n",
    "    @override(SimpleQConfig)\n",
    "    def training(\n",
    "        self,\n",
    "        *,\n",
    "        mixer: Optional[str] = NotProvided,\n",
    "        mixing_embed_dim: Optional[int] = NotProvided,\n",
    "        double_q: Optional[bool] = NotProvided,\n",
    "        target_network_update_freq: Optional[int] = NotProvided,\n",
    "        replay_buffer_config: Optional[dict] = NotProvided,\n",
    "        optim_alpha: Optional[float] = NotProvided,\n",
    "        optim_eps: Optional[float] = NotProvided,\n",
    "        grad_clip: Optional[float] = NotProvided,\n",
    "        # Deprecated args.\n",
    "        grad_norm_clipping=DEPRECATED_VALUE,\n",
    "        **kwargs,\n",
    "    ) -> \"QMixConfig\":\n",
    "        \"\"\"Sets the training related configuration.\n",
    "        Args:\n",
    "            mixer: Mixing network. Either \"qmix\", \"vdn\", or None.\n",
    "            mixing_embed_dim: Size of the mixing network embedding.\n",
    "            double_q: Whether to use Double_Q learning.\n",
    "            target_network_update_freq: Update the target network every\n",
    "                `target_network_update_freq` sample steps.\n",
    "            replay_buffer_config:\n",
    "            optim_alpha: RMSProp alpha.\n",
    "            optim_eps: RMSProp epsilon.\n",
    "            grad_clip: If not None, clip gradients during optimization at\n",
    "                this value.\n",
    "            grad_norm_clipping: Depcrecated in favor of grad_clip\n",
    "        Returns:\n",
    "            This updated AlgorithmConfig object.\n",
    "        \"\"\"\n",
    "        # Pass kwargs onto super's `training()` method.\n",
    "        super().training(**kwargs)\n",
    "\n",
    "        if grad_norm_clipping != DEPRECATED_VALUE:\n",
    "            deprecation_warning(\n",
    "                old=\"grad_norm_clipping\",\n",
    "                new=\"grad_clip\",\n",
    "                help=\"Parameter `grad_norm_clipping` has been \"\n",
    "                \"deprecated in favor of grad_clip in QMix. \"\n",
    "                \"This is now the same parameter as in other \"\n",
    "                \"algorithms. `grad_clip` will be overwritten by \"\n",
    "                \"`grad_norm_clipping={}`\".format(grad_norm_clipping),\n",
    "                error=True,\n",
    "            )\n",
    "            grad_clip = grad_norm_clipping\n",
    "\n",
    "        if mixer is not NotProvided:\n",
    "            self.mixer = mixer\n",
    "        if mixing_embed_dim is not NotProvided:\n",
    "            self.mixing_embed_dim = mixing_embed_dim\n",
    "        if double_q is not NotProvided:\n",
    "            self.double_q = double_q\n",
    "        if target_network_update_freq is not NotProvided:\n",
    "            self.target_network_update_freq = target_network_update_freq\n",
    "        if replay_buffer_config is not NotProvided:\n",
    "            self.replay_buffer_config = replay_buffer_config\n",
    "        if optim_alpha is not NotProvided:\n",
    "            self.optim_alpha = optim_alpha\n",
    "        if optim_eps is not NotProvided:\n",
    "            self.optim_eps = optim_eps\n",
    "        if grad_clip is not NotProvided:\n",
    "            self.grad_clip = grad_clip\n",
    "\n",
    "        return self\n",
    "\n",
    "    @override(SimpleQConfig)\n",
    "    def validate(self) -> None:\n",
    "        # Call super's validation method.\n",
    "        super().validate()\n",
    "\n",
    "        if self.framework_str != \"torch\":\n",
    "            raise ValueError(\n",
    "                \"Only `config.framework('torch')` supported so far for QMix!\"\n",
    "            )\n",
    "\n",
    "class QMix(SimpleQ):\n",
    "    @classmethod\n",
    "    @override(SimpleQ)\n",
    "    def get_default_config(cls) -> AlgorithmConfig:\n",
    "        return QMixConfig()\n",
    "\n",
    "    @classmethod\n",
    "    @override(SimpleQ)\n",
    "    def get_default_policy_class(\n",
    "        cls, config: AlgorithmConfig\n",
    "    ) -> Optional[Type[Policy]]:\n",
    "        return QMixTorchPolicy\n",
    "\n",
    "    @override(SimpleQ)\n",
    "    def training_step(self) -> ResultDict:\n",
    "        \"\"\"QMIX training iteration function.\n",
    "        - Sample n MultiAgentBatches from n workers synchronously.\n",
    "        - Store new samples in the replay buffer.\n",
    "        - Sample one training MultiAgentBatch from the replay buffer.\n",
    "        - Learn on the training batch.\n",
    "        - Update the target network every `target_network_update_freq` sample steps.\n",
    "        - Return all collected training metrics for the iteration.\n",
    "        Returns:\n",
    "            The results dict from executing the training iteration.\n",
    "        \"\"\"\n",
    "        # Sample n batches from n workers.\n",
    "        with self._timers[SAMPLE_TIMER]:\n",
    "            new_sample_batches = synchronous_parallel_sample(\n",
    "                worker_set=self.workers, concat=False\n",
    "            )\n",
    "\n",
    "        for batch in new_sample_batches:\n",
    "            # Update counters.\n",
    "            self._counters[NUM_ENV_STEPS_SAMPLED] += batch.env_steps()\n",
    "            self._counters[NUM_AGENT_STEPS_SAMPLED] += batch.agent_steps()\n",
    "            # Store new samples in the replay buffer.\n",
    "            self.local_replay_buffer.add(batch)\n",
    "\n",
    "        # Update target network every `target_network_update_freq` sample steps.\n",
    "        cur_ts = self._counters[\n",
    "            NUM_AGENT_STEPS_SAMPLED\n",
    "            if self.config.count_steps_by == \"agent_steps\"\n",
    "            else NUM_ENV_STEPS_SAMPLED\n",
    "        ]\n",
    "\n",
    "        train_results = {}\n",
    "\n",
    "        if cur_ts > self.config.num_steps_sampled_before_learning_starts:\n",
    "            # Sample n batches from replay buffer until the total number of timesteps\n",
    "            # reaches `train_batch_size`.\n",
    "            train_batch = sample_min_n_steps_from_buffer(\n",
    "                replay_buffer=self.local_replay_buffer,\n",
    "                min_steps=self.config.train_batch_size,\n",
    "                count_by_agent_steps=self.config.count_steps_by == \"agent_steps\",\n",
    "            )\n",
    "\n",
    "            # Learn on the training batch.\n",
    "            # Use simple optimizer (only for multi-agent or tf-eager; all other\n",
    "            # cases should use the multi-GPU optimizer, even if only using 1 GPU)\n",
    "            if self.config.get(\"simple_optimizer\") is True:\n",
    "                train_results = train_one_step(self, train_batch)\n",
    "            else:\n",
    "                train_results = multi_gpu_train_one_step(self, train_batch)\n",
    "\n",
    "            # Update target network every `target_network_update_freq` sample steps.\n",
    "            last_update = self._counters[LAST_TARGET_UPDATE_TS]\n",
    "            if cur_ts - last_update >= self.config.target_network_update_freq:\n",
    "                to_update = self.workers.local_worker().get_policies_to_train()\n",
    "                self.workers.local_worker().foreach_policy_to_train(\n",
    "                    lambda p, pid: pid in to_update and p.update_target()\n",
    "                )\n",
    "                self._counters[NUM_TARGET_UPDATES] += 1\n",
    "                self._counters[LAST_TARGET_UPDATE_TS] = cur_ts\n",
    "\n",
    "            update_priorities_in_replay_buffer(\n",
    "                self.local_replay_buffer, self.config, train_batch, train_results\n",
    "            )\n",
    "\n",
    "            # Update weights and global_vars - after learning on the local worker -\n",
    "            # on all remote workers.\n",
    "            global_vars = {\n",
    "                \"timestep\": self._counters[NUM_ENV_STEPS_SAMPLED],\n",
    "            }\n",
    "            # Update remote workers' weights and global vars after learning on local\n",
    "            # worker.\n",
    "            with self._timers[SYNCH_WORKER_WEIGHTS_TIMER]:\n",
    "                self.workers.sync_weights(global_vars=global_vars)\n",
    "\n",
    "        # Return all collected metrics for the iteration.\n",
    "        return train_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1263a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.spaces import Dict, Discrete, Tuple, MultiDiscrete\n",
    "b = np.ones(3000).tolist()\n",
    "obs_space= Tuple({MultiDiscrete([])})\n",
    "action_space = Tuple({\n",
    "    \"agent1\": Dict(\n",
    "        {\n",
    "            #\"prob\": Discrete(100),\n",
    "            \"action_potential\": Discrete(1) #excitatory neurons MultiDiscrete([2, 2, 2, 3])\n",
    "        } ,dtype=np.float32),\n",
    "    \"agent2\": Dict(\n",
    "        {\n",
    "            #\"prob\": Discrete(100),\n",
    "            \"action_potential\": Discrete(1) #inhibitory neurons MultiDiscrete([2, 2, 2, 3])\n",
    "        } ,dtype=np.float32),\n",
    "    \"agent3\": Dict(\n",
    "        {\n",
    "            #\"prob\": Discrete(100),\n",
    "            \"outsideAction\":gym.spaces.Box(low=-1.0, high=1.0, shape=(10,)),#this should be replaced with the action space of inverted pendulum\n",
    "            \"action_potential\": Discrete(1)# only excitatory\n",
    "        }, dtype=np.float32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80f96a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.rllib.utils.tf_utils.get_gpu_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "68285dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()\n",
    "#ray.init(num_cpus=16,num_gpus=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a059a7e",
   "metadata": {},
   "source": [
    "main priority as of march 1st: determine the agent network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "088f2a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 22:25:24,751\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8267 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-03-03 22:26:36</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:06.59        </td></tr>\n",
       "<tr><td>Memory:      </td><td>35.5/63.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/17.93 GiB heap, 0.0/8.97 GiB objects (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PG_TwoStepGame_5c0b6_00000</td><td>TERMINATED</td><td>127.0.0.1:57876</td><td style=\"text-align: right;\">   175</td><td style=\"text-align: right;\">         49.6294</td><td style=\"text-align: right;\">70000</td><td style=\"text-align: right;\">    7.01</td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                 2</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m   _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=57876)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(PG pid=57876)\u001b[0m 2023-03-03 22:25:42,113\tWARNING algorithm_config.py:488 -- Cannot create PGConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(PG pid=57876)\u001b[0m 2023-03-03 22:25:42,337\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(PG pid=57876)\u001b[0m 2023-03-03 22:25:42,339\tWARNING env.py:51 -- Skipping env checking for this experiment\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                            </th><th>custom_metrics  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th>info                                                                                                                                                                                                                                                                                                                                                                                                                           </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf  </th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                      </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      </th><th>timers                                                                                                                                                                          </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PG_TwoStepGame_5c0b6_00000</td><td style=\"text-align: right;\">                  70000</td><td>{&#x27;num_env_steps_sampled&#x27;: 70000, &#x27;num_env_steps_trained&#x27;: 70000, &#x27;num_agent_steps_sampled&#x27;: 70000, &#x27;num_agent_steps_trained&#x27;: 70000}</td><td>{}              </td><td style=\"text-align: right;\">                 2</td><td>{}             </td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">                 7.01</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                 100</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;policy_loss&#x27;: 1.332001268863678, &#x27;cur_lr&#x27;: 0.0004}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 200.0, &#x27;num_grad_updates_lifetime&#x27;: 349.5, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 0.5}}, &#x27;num_env_steps_sampled&#x27;: 70000, &#x27;num_env_steps_trained&#x27;: 70000, &#x27;num_agent_steps_sampled&#x27;: 70000, &#x27;num_agent_steps_trained&#x27;: 70000}</td><td style=\"text-align: right;\">                    70000</td><td style=\"text-align: right;\">                    70000</td><td style=\"text-align: right;\">                  70000</td><td style=\"text-align: right;\">                              400</td><td style=\"text-align: right;\">                  70000</td><td style=\"text-align: right;\">                              400</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                          400</td><td>{}    </td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 0.4863756383672068, &#x27;mean_inference_ms&#x27;: 0.7973657785519573, &#x27;mean_action_processing_ms&#x27;: 0.047626687725565546, &#x27;mean_env_wait_ms&#x27;: 0.03705866380894628, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: 8.0, &#x27;episode_reward_min&#x27;: 7.0, &#x27;episode_reward_mean&#x27;: 7.01, &#x27;episode_len_mean&#x27;: 2.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 100, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 8.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0], &#x27;episode_lengths&#x27;: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 0.4863756383672068, &#x27;mean_inference_ms&#x27;: 0.7973657785519573, &#x27;mean_action_processing_ms&#x27;: 0.047626687725565546, &#x27;mean_env_wait_ms&#x27;: 0.03705866380894628, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}</td><td>{&#x27;training_iteration_time_ms&#x27;: 271.231, &#x27;load_time_ms&#x27;: 0.2, &#x27;load_throughput&#x27;: 1999191.611, &#x27;learn_time_ms&#x27;: 6.743, &#x27;learn_throughput&#x27;: 59320.97, &#x27;synch_weights_time_ms&#x27;: 0.0}</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorboardX\\summary.py:234: DeprecationWarning: using `dtype=` in comparisons is only useful for `dtype=object` (and will do nothing for bool). This operation will fail in the future.\n",
      "  cum_counts = np.cumsum(np.greater(counts, 0, dtype=np.int32))\n",
      "2023-03-03 22:26:36,520\tINFO tune.py:762 -- Total run time: 66.76 seconds (66.58 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from gym.spaces import Dict, Discrete, Tuple, MultiDiscrete\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import ray\n",
    "from ray import air, tune\n",
    "from ray.tune import register_env\n",
    "from ray.rllib.env.multi_agent_env import ENV_STATE\n",
    "from ray.rllib.examples.env.two_step_game import TwoStepGame\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "from ray.rllib.utils.test_utils import check_learning_achieved\n",
    "from ray.tune.registry import get_trainable_cls\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--run\", type=str, default=\"PG\", help=\"The RLlib-registered algorithm to use.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--framework\",\n",
    "    choices=[\"tf\", \"tf2\", \"torch\"],\n",
    "    default=\"torch\",\n",
    "    help=\"The DL framework specifier.\",\n",
    ")\n",
    "parser.add_argument(\"--num-cpus\", type=int, default=16)\n",
    "parser.add_argument(\"--num-gpus\", type=int, default=1)\n",
    "parser.add_argument(\n",
    "    \"--mixer\",\n",
    "    type=str,\n",
    "    default=\"qmix\",\n",
    "    choices=[\"qmix\", \"vdn\", \"none\"],\n",
    "    help=\"The mixer model to use.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--as-test\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Whether this script should be run as a test: --stop-reward must \"\n",
    "    \"be achieved within --stop-timesteps AND --stop-iters.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--stop-iters\", type=int, default=200, help=\"Number of iterations to train.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--stop-timesteps\", type=int, default=70000, help=\"Number of timesteps to train.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--stop-reward\", type=float, default=8.0, help=\"Reward at which we stop training.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--local-mode\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Init Ray in local mode for easier debugging.\",\n",
    ")\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #def policy_mapping_fn(agent_id, episode, worker, **kwargs):\n",
    "            #if agent_id.startswith(\"low_level_\"):\n",
    "                #return \"low_level_policy\"\n",
    "            #else:\n",
    "                #return \"high_level_policy\"\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    ray.init(num_cpus=16, num_gpus=1,local_mode=args.local_mode)\n",
    "\n",
    "    grouping = {\n",
    "        \"group_1\": [0],\n",
    "        \"group_2\": [1]\n",
    "    }\n",
    "    obs_space = Tuple(\n",
    "        [\n",
    "            Dict(\n",
    "                {\n",
    "                    \"obs\": MultiDiscrete([2, 2, 2, 3]), \n",
    "                    ENV_STATE: MultiDiscrete([2, 2, 2,1]),\n",
    "                }\n",
    "            ),\n",
    "            Dict(\n",
    "                {\n",
    "                    \"obs\": MultiDiscrete([2, 2, 2, 3]),\n",
    "                    ENV_STATE: MultiDiscrete([2, 2, 2,1]),\n",
    "                }\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    act_space = Tuple(\n",
    "        [\n",
    "            TwoStepGame.action_space,\n",
    "            TwoStepGame.action_space,\n",
    "        ]\n",
    "    )\n",
    "    register_env(\n",
    "        \"grouped_twostep\",\n",
    "        lambda config: TwoStepGame(config).with_agent_groups(\n",
    "            grouping, obs_space=obs_space, act_space=act_space\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    config = (\n",
    "        get_trainable_cls(args.run)\n",
    "        .get_default_config()\n",
    "        .environment(TwoStepGame)\n",
    "        .framework(args.framework)\n",
    "        # Use GPUs iff `RLLIB_NUM_GPUS` env var set to > 0.\n",
    "        .resources(num_gpus=int(os.environ.get(\"RLLIB_NUM_GPUS\", \"0\")))\n",
    "    )\n",
    "\n",
    "    if args.run == \"QMIX\":\n",
    "        (\n",
    "            config.framework(\"torch\")\n",
    "            .training(mixer=args.mixer, train_batch_size=32)\n",
    "            \n",
    "            .multi_agent(\n",
    "                policies={\n",
    "                    \"high_level_policy\": (\n",
    "                        None,\n",
    "                        obs_space,\n",
    "                        act_space,\n",
    "                        #config.overrides(gamma=0.9),\n",
    "                    ),\n",
    "                    \"low_level_policy\": (\n",
    "                        None,\n",
    "                        Tuple([obs_space]),#, Discrete(4)]),\n",
    "                        act_space,\n",
    "                        config.overrides(gamma=0.0),\n",
    "                    ),\n",
    "                },\n",
    "                policy_mapping_fn=policy_mapping_fn,\n",
    "            )\n",
    "            .rollouts(num_rollout_workers=16, rollout_fragment_length=4)\n",
    "            .exploration(\n",
    "                exploration_config={\n",
    "                    \"final_epsilon\": 0.0,\n",
    "                }\n",
    "            )\n",
    "            .environment(\n",
    "                env=\"grouped_twostep\",\n",
    "                env_config={\n",
    "                    \"separate_state_space\": True,\n",
    "                    \"one_hot_state_encoding\": True,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    stop = {\n",
    "        \"episode_reward_mean\": args.stop_reward,\n",
    "        \"timesteps_total\": args.stop_timesteps,\n",
    "        \"training_iteration\": args.stop_iters,\n",
    "    }\n",
    "\n",
    "    results = tune.Tuner(\n",
    "        args.run,\n",
    "        run_config=air.RunConfig(stop=stop, verbose=2),\n",
    "        param_space=config,\n",
    "    ).fit()\n",
    "\n",
    "    if args.as_test:\n",
    "        check_learning_achieved(results, args.stop_reward)\n",
    "\n",
    "    ray.shutdown()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7785c922",
   "metadata": {},
   "source": [
    "0.37 policy loss with prior precision 100\n",
    "\n",
    "0.9271736741065979 policy loss with prior precision of 1\n",
    "0.55 policy loss prior precision of 0.0001\n",
    "\n",
    "0.96 policy loss with prior precision of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c90aaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 23:55:00,110\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': None, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 4, 'batch_mode': 'complete_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.9, 'lr': 0.01, 'train_batch_size': 32, 'model': {'lstm_cell_size': 64, 'max_seq_len': 999999}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.01, 'epsilon_timesteps': 40000}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'explore': False}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': -1, 'replay_sequence_length': None, 'target_network_update_freq': 500, 'replay_buffer_config': {'type': 'ReplayBuffer', 'prioritized_replay': -1, 'capacity': 1000, 'storage_unit': 'fragments', 'worker_side_prioritization': False}, 'num_steps_sampled_before_learning_starts': 1000, 'store_buffer_in_checkpoints': False, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 10, 'tau': 1.0, 'mixer': 'qmix', 'mixing_embed_dim': 32, 'double_q': True, 'optim_alpha': 0.99, 'optim_eps': 1e-05, 'worker_side_prioritization': -1, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x0000020883583280>}, 'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x0000020880109B80>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 23:55:03,732\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8267 \u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=2216)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m   _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=51868)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m   _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=23656)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m   _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=37192)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m   _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=31944)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m   _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39208)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m   _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=3564)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m   _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=33212)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m   _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=44332)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m   _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=39784)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m   _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52428)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m   _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m   _descriptor.EnumValueDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m   _DATATYPE = _descriptor.EnumDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m   _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m   _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m   _TENSORPROTO = _descriptor.Descriptor(\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m   DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "\u001b[2m\u001b[36m(pid=52744)\u001b[0m   _descriptor.FieldDescriptor(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2216)\u001b[0m 2023-03-01 23:55:22,808\tWARNING env.py:51 -- Skipping env checking for this experiment\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2216)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\algorithms\\qmix\\qmix_policy.py:520: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2216)\u001b[0m   k: torch.as_tensor(v, device=self.device) for k, v in state_dict.items()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=31944)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\algorithms\\qmix\\qmix_policy.py:520: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=31944)\u001b[0m   k: torch.as_tensor(v, device=self.device) for k, v in state_dict.items()\n",
      "2023-03-01 23:55:24,479\tINFO trainable.py:172 -- Trainable.setup took 24.369 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2023-03-01 23:55:24,529\tERROR actor_manager.py:486 -- Ray error, taking actor 1 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=2216, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000001353236C6D0>)\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([0, 1, 0, 0], dtype=int64)), ('state', array([1, 1, 0, 0], dtype=int64))]), OrderedDict([('obs', array([0, 1, 1, 1], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([0, 1, 0, 0], dtype=int64)), ('state', array([1, 1, 0, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=2216, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000001353236C6D0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 671, in _env_runner\n",
      "    active_envs, to_eval, outputs = _process_observations(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 922, in _process_observations\n",
      "    prep_obs = preprocessor.transform(raw_obs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 246, in transform\n",
      "    self.check_shape(observation)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 69, in check_shape\n",
      "    observation = convert_element_to_space_type(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\spaces\\space_utils.py\", line 359, in convert_element_to_space_type\n",
      "    return tree.map_structure(map_, element, sampled_element, check_types=False)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 428, in map_structure\n",
      "    assert_same_structure(structures[0], other, check_types=check_types)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 284, in assert_same_structure\n",
      "    raise type(e)(\"%s\\n\"\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([0, 1, 0, 0], dtype=int64)), ('state', array([1, 1, 0, 0], dtype=int64))]), OrderedDict([('obs', array([0, 1, 1, 1], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([0, 1, 0, 0], dtype=int64)), ('state', array([1, 1, 0, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "Entire first structure:\n",
      "[.]\n",
      "Entire second structure:\n",
      "(OrderedDict([('obs', .), ('state', .)]), OrderedDict([('obs', .), ('state', .)]))\n",
      "2023-03-01 23:55:24,532\tERROR actor_manager.py:486 -- Ray error, taking actor 2 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=31944, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000022CC9E9C640>)\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([1, 0, 1, 2], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))]), OrderedDict([('obs', array([1, 0, 1, 2], dtype=int64)), ('state', array([0, 0, 0, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([1, 0, 1, 2], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=31944, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000022CC9E9C640>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 671, in _env_runner\n",
      "    active_envs, to_eval, outputs = _process_observations(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 922, in _process_observations\n",
      "    prep_obs = preprocessor.transform(raw_obs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 246, in transform\n",
      "    self.check_shape(observation)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 69, in check_shape\n",
      "    observation = convert_element_to_space_type(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\spaces\\space_utils.py\", line 359, in convert_element_to_space_type\n",
      "    return tree.map_structure(map_, element, sampled_element, check_types=False)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 428, in map_structure\n",
      "    assert_same_structure(structures[0], other, check_types=check_types)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 284, in assert_same_structure\n",
      "    raise type(e)(\"%s\\n\"\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([1, 0, 1, 2], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))]), OrderedDict([('obs', array([1, 0, 1, 2], dtype=int64)), ('state', array([0, 0, 0, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([1, 0, 1, 2], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "Entire first structure:\n",
      "[.]\n",
      "Entire second structure:\n",
      "(OrderedDict([('obs', .), ('state', .)]), OrderedDict([('obs', .), ('state', .)]))\n",
      "2023-03-01 23:55:24,533\tERROR actor_manager.py:486 -- Ray error, taking actor 3 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=3564, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000027B9706C670>)\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([1, 0, 0, 1], dtype=int64)), ('state', array([1, 1, 1, 0], dtype=int64))]), OrderedDict([('obs', array([0, 1, 0, 0], dtype=int64)), ('state', array([0, 0, 0, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([1, 0, 0, 1], dtype=int64)), ('state', array([1, 1, 1, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=3564, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000027B9706C670>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 671, in _env_runner\n",
      "    active_envs, to_eval, outputs = _process_observations(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 922, in _process_observations\n",
      "    prep_obs = preprocessor.transform(raw_obs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 246, in transform\n",
      "    self.check_shape(observation)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 69, in check_shape\n",
      "    observation = convert_element_to_space_type(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\spaces\\space_utils.py\", line 359, in convert_element_to_space_type\n",
      "    return tree.map_structure(map_, element, sampled_element, check_types=False)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 428, in map_structure\n",
      "    assert_same_structure(structures[0], other, check_types=check_types)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 284, in assert_same_structure\n",
      "    raise type(e)(\"%s\\n\"\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([1, 0, 0, 1], dtype=int64)), ('state', array([1, 1, 1, 0], dtype=int64))]), OrderedDict([('obs', array([0, 1, 0, 0], dtype=int64)), ('state', array([0, 0, 0, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([1, 0, 0, 1], dtype=int64)), ('state', array([1, 1, 1, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "Entire first structure:\n",
      "[.]\n",
      "Entire second structure:\n",
      "(OrderedDict([('obs', .), ('state', .)]), OrderedDict([('obs', .), ('state', .)]))\n",
      "2023-03-01 23:55:24,536\tERROR actor_manager.py:486 -- Ray error, taking actor 4 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=39208, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000026B1706B700>)\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([1, 1, 1, 2], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))]), OrderedDict([('obs', array([0, 1, 1, 1], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([1, 1, 1, 2], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=39208, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000026B1706B700>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 671, in _env_runner\n",
      "    active_envs, to_eval, outputs = _process_observations(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 922, in _process_observations\n",
      "    prep_obs = preprocessor.transform(raw_obs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 246, in transform\n",
      "    self.check_shape(observation)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 69, in check_shape\n",
      "    observation = convert_element_to_space_type(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\spaces\\space_utils.py\", line 359, in convert_element_to_space_type\n",
      "    return tree.map_structure(map_, element, sampled_element, check_types=False)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 428, in map_structure\n",
      "    assert_same_structure(structures[0], other, check_types=check_types)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 284, in assert_same_structure\n",
      "    raise type(e)(\"%s\\n\"\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([1, 1, 1, 2], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))]), OrderedDict([('obs', array([0, 1, 1, 1], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([1, 1, 1, 2], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "Entire first structure:\n",
      "[.]\n",
      "Entire second structure:\n",
      "(OrderedDict([('obs', .), ('state', .)]), OrderedDict([('obs', .), ('state', .)]))\n",
      "2023-03-01 23:55:24,539\tERROR actor_manager.py:486 -- Ray error, taking actor 5 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=37192, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000022F3BE4B700>)\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([0, 0, 0, 2], dtype=int64)), ('state', array([1, 1, 1, 0], dtype=int64))]), OrderedDict([('obs', array([0, 0, 0, 0], dtype=int64)), ('state', array([1, 0, 1, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([0, 0, 0, 2], dtype=int64)), ('state', array([1, 1, 1, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=37192, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000022F3BE4B700>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 671, in _env_runner\n",
      "    active_envs, to_eval, outputs = _process_observations(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 922, in _process_observations\n",
      "    prep_obs = preprocessor.transform(raw_obs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 246, in transform\n",
      "    self.check_shape(observation)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 69, in check_shape\n",
      "    observation = convert_element_to_space_type(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\spaces\\space_utils.py\", line 359, in convert_element_to_space_type\n",
      "    return tree.map_structure(map_, element, sampled_element, check_types=False)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 428, in map_structure\n",
      "    assert_same_structure(structures[0], other, check_types=check_types)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 284, in assert_same_structure\n",
      "    raise type(e)(\"%s\\n\"\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([0, 0, 0, 2], dtype=int64)), ('state', array([1, 1, 1, 0], dtype=int64))]), OrderedDict([('obs', array([0, 0, 0, 0], dtype=int64)), ('state', array([1, 0, 1, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([0, 0, 0, 2], dtype=int64)), ('state', array([1, 1, 1, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "Entire first structure:\n",
      "[.]\n",
      "Entire second structure:\n",
      "(OrderedDict([('obs', .), ('state', .)]), OrderedDict([('obs', .), ('state', .)]))\n",
      "2023-03-01 23:55:24,540\tERROR actor_manager.py:486 -- Ray error, taking actor 6 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=23656, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000002AC49E9C670>)\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([1, 1, 0, 2], dtype=int64)), ('state', array([0, 0, 1, 0], dtype=int64))]), OrderedDict([('obs', array([0, 0, 1, 1], dtype=int64)), ('state', array([0, 0, 1, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([1, 1, 0, 2], dtype=int64)), ('state', array([0, 0, 1, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=23656, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000002AC49E9C670>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 671, in _env_runner\n",
      "    active_envs, to_eval, outputs = _process_observations(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 922, in _process_observations\n",
      "    prep_obs = preprocessor.transform(raw_obs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 246, in transform\n",
      "    self.check_shape(observation)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 69, in check_shape\n",
      "    observation = convert_element_to_space_type(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\spaces\\space_utils.py\", line 359, in convert_element_to_space_type\n",
      "    return tree.map_structure(map_, element, sampled_element, check_types=False)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 428, in map_structure\n",
      "    assert_same_structure(structures[0], other, check_types=check_types)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 284, in assert_same_structure\n",
      "    raise type(e)(\"%s\\n\"\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([1, 1, 0, 2], dtype=int64)), ('state', array([0, 0, 1, 0], dtype=int64))]), OrderedDict([('obs', array([0, 0, 1, 1], dtype=int64)), ('state', array([0, 0, 1, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([1, 1, 0, 2], dtype=int64)), ('state', array([0, 0, 1, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "Entire first structure:\n",
      "[.]\n",
      "Entire second structure:\n",
      "(OrderedDict([('obs', .), ('state', .)]), OrderedDict([('obs', .), ('state', .)]))\n",
      "2023-03-01 23:55:24,541\tERROR actor_manager.py:486 -- Ray error, taking actor 7 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=51868, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000001821CC3C640>)\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([0, 1, 0, 1], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))]), OrderedDict([('obs', array([1, 1, 1, 0], dtype=int64)), ('state', array([0, 0, 1, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([0, 1, 0, 1], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=51868, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000001821CC3C640>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 671, in _env_runner\n",
      "    active_envs, to_eval, outputs = _process_observations(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 922, in _process_observations\n",
      "    prep_obs = preprocessor.transform(raw_obs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 246, in transform\n",
      "    self.check_shape(observation)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 69, in check_shape\n",
      "    observation = convert_element_to_space_type(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\spaces\\space_utils.py\", line 359, in convert_element_to_space_type\n",
      "    return tree.map_structure(map_, element, sampled_element, check_types=False)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 428, in map_structure\n",
      "    assert_same_structure(structures[0], other, check_types=check_types)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 284, in assert_same_structure\n",
      "    raise type(e)(\"%s\\n\"\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([0, 1, 0, 1], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))]), OrderedDict([('obs', array([1, 1, 1, 0], dtype=int64)), ('state', array([0, 0, 1, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([0, 1, 0, 1], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "Entire first structure:\n",
      "[.]\n",
      "Entire second structure:\n",
      "(OrderedDict([('obs', .), ('state', .)]), OrderedDict([('obs', .), ('state', .)]))\n",
      "2023-03-01 23:55:24,543\tERROR actor_manager.py:486 -- Ray error, taking actor 8 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=33212, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000027BA60EC6A0>)\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([1, 1, 0, 2], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))]), OrderedDict([('obs', array([1, 1, 1, 1], dtype=int64)), ('state', array([1, 0, 1, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([1, 1, 0, 2], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=33212, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000027BA60EC6A0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 671, in _env_runner\n",
      "    active_envs, to_eval, outputs = _process_observations(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 922, in _process_observations\n",
      "    prep_obs = preprocessor.transform(raw_obs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 246, in transform\n",
      "    self.check_shape(observation)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 69, in check_shape\n",
      "    observation = convert_element_to_space_type(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\spaces\\space_utils.py\", line 359, in convert_element_to_space_type\n",
      "    return tree.map_structure(map_, element, sampled_element, check_types=False)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 428, in map_structure\n",
      "    assert_same_structure(structures[0], other, check_types=check_types)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 284, in assert_same_structure\n",
      "    raise type(e)(\"%s\\n\"\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([1, 1, 0, 2], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))]), OrderedDict([('obs', array([1, 1, 1, 1], dtype=int64)), ('state', array([1, 0, 1, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([1, 1, 0, 2], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "Entire first structure:\n",
      "[.]\n",
      "Entire second structure:\n",
      "(OrderedDict([('obs', .), ('state', .)]), OrderedDict([('obs', .), ('state', .)]))\n",
      "2023-03-01 23:55:24,545\tERROR actor_manager.py:486 -- Ray error, taking actor 9 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=44332, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000001F19C91C6D0>)\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([1, 0, 0, 1], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))]), OrderedDict([('obs', array([0, 0, 0, 1], dtype=int64)), ('state', array([1, 0, 0, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([1, 0, 0, 1], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=44332, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000001F19C91C6D0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 671, in _env_runner\n",
      "    active_envs, to_eval, outputs = _process_observations(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 922, in _process_observations\n",
      "    prep_obs = preprocessor.transform(raw_obs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 246, in transform\n",
      "    self.check_shape(observation)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 69, in check_shape\n",
      "    observation = convert_element_to_space_type(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\spaces\\space_utils.py\", line 359, in convert_element_to_space_type\n",
      "    return tree.map_structure(map_, element, sampled_element, check_types=False)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 428, in map_structure\n",
      "    assert_same_structure(structures[0], other, check_types=check_types)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 284, in assert_same_structure\n",
      "    raise type(e)(\"%s\\n\"\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([1, 0, 0, 1], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))]), OrderedDict([('obs', array([0, 0, 0, 1], dtype=int64)), ('state', array([1, 0, 0, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([1, 0, 0, 1], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "Entire first structure:\n",
      "[.]\n",
      "Entire second structure:\n",
      "(OrderedDict([('obs', .), ('state', .)]), OrderedDict([('obs', .), ('state', .)]))\n",
      "2023-03-01 23:55:24,546\tERROR actor_manager.py:486 -- Ray error, taking actor 10 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=39784, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000001A93AB4C670>)\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([1, 0, 0, 2], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))]), OrderedDict([('obs', array([1, 1, 1, 0], dtype=int64)), ('state', array([1, 0, 0, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([1, 0, 0, 2], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=39784, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000001A93AB4C670>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 671, in _env_runner\n",
      "    active_envs, to_eval, outputs = _process_observations(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 922, in _process_observations\n",
      "    prep_obs = preprocessor.transform(raw_obs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 246, in transform\n",
      "    self.check_shape(observation)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 69, in check_shape\n",
      "    observation = convert_element_to_space_type(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\spaces\\space_utils.py\", line 359, in convert_element_to_space_type\n",
      "    return tree.map_structure(map_, element, sampled_element, check_types=False)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 428, in map_structure\n",
      "    assert_same_structure(structures[0], other, check_types=check_types)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 284, in assert_same_structure\n",
      "    raise type(e)(\"%s\\n\"\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([1, 0, 0, 2], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))]), OrderedDict([('obs', array([1, 1, 1, 0], dtype=int64)), ('state', array([1, 0, 0, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([1, 0, 0, 2], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "Entire first structure:\n",
      "[.]\n",
      "Entire second structure:\n",
      "(OrderedDict([('obs', .), ('state', .)]), OrderedDict([('obs', .), ('state', .)]))\n",
      "2023-03-01 23:55:24,548\tERROR actor_manager.py:486 -- Ray error, taking actor 11 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=52428, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000001D03F13B700>)\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([0, 0, 1, 2], dtype=int64)), ('state', array([1, 0, 0, 0], dtype=int64))]), OrderedDict([('obs', array([1, 1, 0, 1], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([0, 0, 1, 2], dtype=int64)), ('state', array([1, 0, 0, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=52428, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000001D03F13B700>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 671, in _env_runner\n",
      "    active_envs, to_eval, outputs = _process_observations(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 922, in _process_observations\n",
      "    prep_obs = preprocessor.transform(raw_obs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 246, in transform\n",
      "    self.check_shape(observation)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 69, in check_shape\n",
      "    observation = convert_element_to_space_type(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\spaces\\space_utils.py\", line 359, in convert_element_to_space_type\n",
      "    return tree.map_structure(map_, element, sampled_element, check_types=False)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 428, in map_structure\n",
      "    assert_same_structure(structures[0], other, check_types=check_types)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 284, in assert_same_structure\n",
      "    raise type(e)(\"%s\\n\"\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([0, 0, 1, 2], dtype=int64)), ('state', array([1, 0, 0, 0], dtype=int64))]), OrderedDict([('obs', array([1, 1, 0, 1], dtype=int64)), ('state', array([0, 1, 1, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([0, 0, 1, 2], dtype=int64)), ('state', array([1, 0, 0, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "Entire first structure:\n",
      "[.]\n",
      "Entire second structure:\n",
      "(OrderedDict([('obs', .), ('state', .)]), OrderedDict([('obs', .), ('state', .)]))\n",
      "2023-03-01 23:55:24,551\tERROR actor_manager.py:486 -- Ray error, taking actor 12 out of service. \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=52744, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000015216F6C670>)\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([0, 1, 0, 2], dtype=int64)), ('state', array([0, 0, 0, 0], dtype=int64))]), OrderedDict([('obs', array([1, 0, 1, 2], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([0, 1, 0, 2], dtype=int64)), ('state', array([0, 0, 0, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=52744, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000015216F6C670>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 183, in apply\n",
      "    raise e\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 174, in apply\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py\", line 86, in <lambda>\n",
      "    lambda w: w.sample(), local_worker=False, healthy_only=True\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 900, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 671, in _env_runner\n",
      "    active_envs, to_eval, outputs = _process_observations(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 922, in _process_observations\n",
      "    prep_obs = preprocessor.transform(raw_obs)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 246, in transform\n",
      "    self.check_shape(observation)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 69, in check_shape\n",
      "    observation = convert_element_to_space_type(\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\spaces\\space_utils.py\", line 359, in convert_element_to_space_type\n",
      "    return tree.map_structure(map_, element, sampled_element, check_types=False)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 428, in map_structure\n",
      "    assert_same_structure(structures[0], other, check_types=check_types)\n",
      "  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 284, in assert_same_structure\n",
      "    raise type(e)(\"%s\\n\"\n",
      "ValueError: The two structures don't have the same nested structure.\n",
      "\n",
      "First structure: type=list str=[0]\n",
      "\n",
      "Second structure: type=tuple str=(OrderedDict([('obs', array([0, 1, 0, 2], dtype=int64)), ('state', array([0, 0, 0, 0], dtype=int64))]), OrderedDict([('obs', array([1, 0, 1, 2], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))]))\n",
      "\n",
      "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([0, 1, 0, 2], dtype=int64)), ('state', array([0, 0, 0, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n",
      "Entire first structure:\n",
      "[.]\n",
      "Entire second structure:\n",
      "(OrderedDict([('obs', .), ('state', .)]), OrderedDict([('obs', .), ('state', .)]))\n"
     ]
    },
    {
     "ename": "RayTaskError(ValueError)",
     "evalue": "\u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=2216, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000001353236C6D0>)\nValueError: The two structures don't have the same nested structure.\n\nFirst structure: type=list str=[0]\n\nSecond structure: type=tuple str=(OrderedDict([('obs', array([0, 1, 0, 0], dtype=int64)), ('state', array([1, 1, 0, 0], dtype=int64))]), OrderedDict([('obs', array([0, 1, 1, 1], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))]))\n\nMore specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([0, 1, 0, 0], dtype=int64)), ('state', array([1, 1, 0, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n\nDuring handling of the above exception, another exception occurred:\n\n\u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=2216, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000001353236C6D0>)\n  File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n    return method(self, *_args, **_kwargs)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 183, in apply\n    raise e\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 174, in apply\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py\", line 86, in <lambda>\n    lambda w: w.sample(), local_worker=False, healthy_only=True\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n    return method(self, *_args, **_kwargs)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 900, in sample\n    batches = [self.input_reader.next()]\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 92, in next\n    batches = [self.get_data()]\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 285, in get_data\n    item = next(self._env_runner)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 671, in _env_runner\n    active_envs, to_eval, outputs = _process_observations(\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 922, in _process_observations\n    prep_obs = preprocessor.transform(raw_obs)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 246, in transform\n    self.check_shape(observation)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 69, in check_shape\n    observation = convert_element_to_space_type(\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\spaces\\space_utils.py\", line 359, in convert_element_to_space_type\n    return tree.map_structure(map_, element, sampled_element, check_types=False)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 428, in map_structure\n    assert_same_structure(structures[0], other, check_types=check_types)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 284, in assert_same_structure\n    raise type(e)(\"%s\\n\"\nValueError: The two structures don't have the same nested structure.\n\nFirst structure: type=list str=[0]\n\nSecond structure: type=tuple str=(OrderedDict([('obs', array([0, 1, 0, 0], dtype=int64)), ('state', array([1, 1, 0, 0], dtype=int64))]), OrderedDict([('obs', array([0, 1, 1, 1], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))]))\n\nMore specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([0, 1, 0, 0], dtype=int64)), ('state', array([1, 1, 0, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\nEntire first structure:\n[.]\nEntire second structure:\n(OrderedDict([('obs', .), ('state', .)]), OrderedDict([('obs', .), ('state', .)]))",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\subar\\AppData\\Local\\Temp\\ipykernel_32828\\2355281060.py\"\u001b[0m, line \u001b[0;32m20\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    algo.train()\n",
      "  File \u001b[0;32m\"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\"\u001b[0m, line \u001b[0;32m367\u001b[0m, in \u001b[0;35mtrain\u001b[0m\n    raise skipped from exception_cause(skipped)\n",
      "  File \u001b[0;32m\"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\"\u001b[0m, line \u001b[0;32m364\u001b[0m, in \u001b[0;35mtrain\u001b[0m\n    result = self.step()\n",
      "  File \u001b[0;32m\"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py\"\u001b[0m, line \u001b[0;32m749\u001b[0m, in \u001b[0;35mstep\u001b[0m\n    results, train_iter_ctx = self._run_one_training_iteration()\n",
      "  File \u001b[0;32m\"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py\"\u001b[0m, line \u001b[0;32m2623\u001b[0m, in \u001b[0;35m_run_one_training_iteration\u001b[0m\n    results = self.training_step()\n",
      "  File \u001b[0;32m\"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\algorithms\\qmix\\qmix.py\"\u001b[0m, line \u001b[0;32m255\u001b[0m, in \u001b[0;35mtraining_step\u001b[0m\n    new_sample_batches = synchronous_parallel_sample(\n",
      "  File \u001b[0;32m\"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py\"\u001b[0m, line \u001b[0;32m85\u001b[0m, in \u001b[0;35msynchronous_parallel_sample\u001b[0m\n    sample_batches = worker_set.foreach_worker(\n",
      "  File \u001b[0;32m\"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py\"\u001b[0m, line \u001b[0;32m696\u001b[0m, in \u001b[0;35mforeach_worker\u001b[0m\n    handle_remote_call_result_errors(remote_results, self._ignore_worker_failures)\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py\"\u001b[1;36m, line \u001b[1;32m73\u001b[1;36m, in \u001b[1;35mhandle_remote_call_result_errors\u001b[1;36m\u001b[0m\n\u001b[1;33m    raise r.get()\u001b[0m\n",
      "\u001b[1;31mRayTaskError(ValueError)\u001b[0m\u001b[1;31m:\u001b[0m \u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=2216, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000001353236C6D0>)\nValueError: The two structures don't have the same nested structure.\n\nFirst structure: type=list str=[0]\n\nSecond structure: type=tuple str=(OrderedDict([('obs', array([0, 1, 0, 0], dtype=int64)), ('state', array([1, 1, 0, 0], dtype=int64))]), OrderedDict([('obs', array([0, 1, 1, 1], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))]))\n\nMore specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([0, 1, 0, 0], dtype=int64)), ('state', array([1, 1, 0, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\n\nDuring handling of the above exception, another exception occurred:\n\n\u001b[36mray::RolloutWorker.apply()\u001b[39m (pid=2216, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000001353236C6D0>)\n  File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n    return method(self, *_args, **_kwargs)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 183, in apply\n    raise e\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 174, in apply\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py\", line 86, in <lambda>\n    lambda w: w.sample(), local_worker=False, healthy_only=True\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n    return method(self, *_args, **_kwargs)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 900, in sample\n    batches = [self.input_reader.next()]\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 92, in next\n    batches = [self.get_data()]\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 285, in get_data\n    item = next(self._env_runner)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 671, in _env_runner\n    active_envs, to_eval, outputs = _process_observations(\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\evaluation\\sampler.py\", line 922, in _process_observations\n    prep_obs = preprocessor.transform(raw_obs)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 246, in transform\n    self.check_shape(observation)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\models\\preprocessors.py\", line 69, in check_shape\n    observation = convert_element_to_space_type(\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\utils\\spaces\\space_utils.py\", line 359, in convert_element_to_space_type\n    return tree.map_structure(map_, element, sampled_element, check_types=False)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 428, in map_structure\n    assert_same_structure(structures[0], other, check_types=check_types)\n  File \"C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\tree\\__init__.py\", line 284, in assert_same_structure\n    raise type(e)(\"%s\\n\"\nValueError: The two structures don't have the same nested structure.\n\nFirst structure: type=list str=[0]\n\nSecond structure: type=tuple str=(OrderedDict([('obs', array([0, 1, 0, 0], dtype=int64)), ('state', array([1, 1, 0, 0], dtype=int64))]), OrderedDict([('obs', array([0, 1, 1, 1], dtype=int64)), ('state', array([0, 1, 0, 0], dtype=int64))]))\n\nMore specifically: Substructure \"type=OrderedDict str=OrderedDict([('obs', array([0, 1, 0, 0], dtype=int64)), ('state', array([1, 1, 0, 0], dtype=int64))])\" is a sequence, while substructure \"type=int64 str=0\" is not\nEntire first structure:\n[.]\nEntire second structure:\n(OrderedDict([('obs', .), ('state', .)]), OrderedDict([('obs', .), ('state', .)]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=51868)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\algorithms\\qmix\\qmix_policy.py:520: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=51868)\u001b[0m   k: torch.as_tensor(v, device=self.device) for k, v in state_dict.items()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=23656)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\algorithms\\qmix\\qmix_policy.py:520: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=23656)\u001b[0m   k: torch.as_tensor(v, device=self.device) for k, v in state_dict.items()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37192)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\algorithms\\qmix\\qmix_policy.py:520: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=37192)\u001b[0m   k: torch.as_tensor(v, device=self.device) for k, v in state_dict.items()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=39208)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\algorithms\\qmix\\qmix_policy.py:520: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=39208)\u001b[0m   k: torch.as_tensor(v, device=self.device) for k, v in state_dict.items()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3564)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\algorithms\\qmix\\qmix_policy.py:520: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3564)\u001b[0m   k: torch.as_tensor(v, device=self.device) for k, v in state_dict.items()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=33212)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\algorithms\\qmix\\qmix_policy.py:520: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=33212)\u001b[0m   k: torch.as_tensor(v, device=self.device) for k, v in state_dict.items()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=44332)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\algorithms\\qmix\\qmix_policy.py:520: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=44332)\u001b[0m   k: torch.as_tensor(v, device=self.device) for k, v in state_dict.items()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=39784)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\algorithms\\qmix\\qmix_policy.py:520: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=39784)\u001b[0m   k: torch.as_tensor(v, device=self.device) for k, v in state_dict.items()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=52428)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\algorithms\\qmix\\qmix_policy.py:520: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=52428)\u001b[0m   k: torch.as_tensor(v, device=self.device) for k, v in state_dict.items()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=52744)\u001b[0m C:\\Users\\subar\\anaconda3\\envs\\d\\lib\\site-packages\\ray\\rllib\\algorithms\\qmix\\qmix_policy.py:520: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=52744)\u001b[0m   k: torch.as_tensor(v, device=self.device) for k, v in state_dict.items()\n"
     ]
    }
   ],
   "source": [
    "#from ray.rllib.examples.env.two_step_game import TwoStepGame\n",
    "\n",
    "#it lacks the full paremterizan of above cell. That my be the cause of the error\n",
    "\n",
    "from ray.rllib.algorithms.qmix import QMixConfig\n",
    "config = QMixConfig()  \n",
    "config = config.training(gamma=0.9, lr=0.01)#, kl_coeff=0.3)  \n",
    "#config = config.resources(num_gpus=0)  \n",
    "config = config.rollouts(num_rollout_workers=12)  \n",
    "print(config.to_dict())  \n",
    "# Build an Algorithm object from the config and run 1 training iteration.\n",
    "register_env(\n",
    "    \"grouped_twostep\",\n",
    "    lambda config: TwoStepGame(config).with_agent_groups(\n",
    "        grouping, obs_space=obs_space, act_space=act_space\n",
    "    ),\n",
    ")\n",
    "\n",
    "algo = config.build(env=\"grouped_twostep\")  \n",
    "algo.train() \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "145ccad1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ecf1de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
