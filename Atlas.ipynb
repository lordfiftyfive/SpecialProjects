{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 17:19:58.658743: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-13 17:19:58.694069: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-13 17:19:59.311085: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from alpaca_trade_api.stream import Stream\n",
    "import alpaca_trade_api as tradeapi\n",
    "import time\n",
    "#from numba import jit\n",
    "import numpy as np \n",
    "import cupy as cp\n",
    "from cupy import ndarray\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "#import py_vollib.black_scholes\n",
    "#import markowitzify\n",
    "#pd.isnull(np.datetime64('NaT'))\n",
    "#from pipeline_live.data.alpaca.factors import AverageDollarVolume\n",
    "#from pipeline_live.data.alpaca.pricing import USEquityPricing\n",
    "\n",
    "from zipline.finance import commission, slippage\n",
    "from zipline.pipeline import Pipeline\n",
    "from zipline.pipeline.factors import (RSI, AverageDollarVolume, BollingerBands, DailyReturns,\n",
    "ExponentialWeightedMovingAverage, MACDSignal, MaxDrawdown, Returns, RollingPearson,RollingSpearman,VWAP,CustomFactor)\n",
    "from zipline.pipeline.filters import AtLeastN\n",
    "from zipline.api import (\n",
    "    attach_pipeline,\n",
    "    order_target_percent,\n",
    "    pipeline_output,\n",
    "    record,\n",
    "    schedule_function,\n",
    "    date_rules,\n",
    "    time_rules\n",
    ")\n",
    "#note alpaca has all of the same factors as zipline\n",
    "\"\"\"\n",
    "from pipeline_live.data.alpaca.factors import (\n",
    "    RSI,MACDSignal,VWAP,AverageDollarVolume, SimpleMovingAverage,\n",
    ")\n",
    "\"\"\"\n",
    "#from pylivetrader.api import order_target, symbol\n",
    "#import numba_scipy\n",
    "#import alphalens as al\n",
    "#import tensorflow_probability as tfp\n",
    "#from tensorflow_probability import bijectors as tfb\n",
    "#from tensorflow_probability.python.math import psd_kernels as tfk\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "#from prophet.plot import plot_plotly, plot_components_plotly\n",
    "#from prophet import Prophet\n",
    "#from tensortrade.data.cdd import CryptoDataDownload\n",
    "\n",
    "from alpaca_trade_api.rest import TimeFrame\n",
    "import polars as pl\n",
    "import statistics\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "#import pyfolio as pf\n",
    "from datetime import datetime, timedelta\n",
    "from pytz import timezone\n",
    "from alpaca_trade_api.rest_async import gather_with_concurrency, AsyncRest\n",
    "from tiingo import TiingoClient\n",
    "from websocket import create_connection\n",
    "import simfin as sf\n",
    "from simfin.names import *\n",
    "#from tiingo import TiingoWebsocketClient\n",
    "import jax.numpy as jnp\n",
    "#hyper parameter optimization\n",
    "\n",
    "\n",
    "\n",
    "#bring cudf-polars \n",
    "\n",
    "#core time series prediction library\n",
    "from darts import TimeSeries\n",
    "from darts.models import DLinearModel, TiDEModel, TFTModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cudf import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#, DLinearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT ID\n",
    "FROM TABLE\n",
    "WHERE ID > 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cupy\n",
    "from cuml.cluster import DBSCAN\n",
    "from cuml.decomposition import PCA\n",
    "from cuml import ExponentialSmoothing\n",
    "from cuml import UMAP\n",
    "#from cuml.neighbors import NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "# To reuse the same HTTP Session across API calls (and have better performance), include a session key.\n",
    "config['session'] = True\n",
    "\n",
    "config['api_key'] = \"292879b75e4ce811056b97bbbf8d72ca04e20de8\"\n",
    "\n",
    "client = TiingoClient(config)\n",
    "API_KEY = \"AKMLXVPKAQU1M9FWDYPZ\"\n",
    "API_SECRET = \"oaCSrDz2Be4GYeEI8SSQGYEpdS1AiJvYOn3eUjcO\"#oaCSrDz2Be4GYeEI8SSQGYEpdS1AiJvYOn3eUjcO\n",
    "APCA_API_BASE_URL = \"https://api.alpaca.markets\"\n",
    "alpaca = tradeapi.REST(API_KEY, API_SECRET, APCA_API_BASE_URL, 'v2')\n",
    "api = alpaca\n",
    "assets = api.list_assets()\n",
    "Scalar = MinMaxScaler(feature_range=(-1,1))\n",
    "pca = PCA()\n",
    "index = 0\n",
    "api_time_format = '%Y-%m-%dT%H:%M:%S.%f-04:00'\n",
    "stocks_to_hold = 150\n",
    "ws = create_connection(\"wss://api.tiingo.com/iex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.set_data_dir('~/simfin_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.set_api_key(api_key='7BcfsY04I70RRlaA0vtvBSSXmnvpPTxS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"us-shareprices-daily\" on disk (7 days old).\n",
      "- Loading from disk ... Done!\n"
     ]
    }
   ],
   "source": [
    "offset = pd.DateOffset(days=60)\n",
    "refresh_days = 30\n",
    "\n",
    "refresh_days_shareprices = 10\n",
    "\n",
    "def dat():#algo_time\n",
    "  #pipeline_data = context.pipeline_data\n",
    "  #all_assets = pipeline_data.index\n",
    "\n",
    "  #longs = all_assets[pipeline_data.longs]\n",
    "  #shorts = all_assets[pipeline_data.shorts]\n",
    "  \n",
    "  #hub = sf.StockHub(market='us', offset=offset,refresh_days=refresh_days,refresh_days_shareprices=refresh_days_shareprices)\n",
    "  market = 'us'\n",
    "  offset = pd.DateOffset(days=60)\n",
    "  refresh_days = 30\n",
    "\n",
    "  # Refresh the dataset with shareprices every 10 days.\n",
    "  refresh_days_shareprices = 10\n",
    "\n",
    "  hub = sf.StockHub(market=market, offset=offset,\n",
    "                  refresh_days=refresh_days,\n",
    "                  refresh_days_shareprices=refresh_days_shareprices)\n",
    "  x0 = sf.load_shareprices(market='us', variant='daily')\n",
    "  #x1 = sf.load_income_banks(market='us',variant='daily')\n",
    "  #tickers = client.list_stock_tickers()\n",
    "  #x4 = client.get_fundamentals_daily([tickers],startDate='2020-01-01',endDate='2020-12-31')\n",
    "  #x1 =hub.growth_signals(variant='daily')#hub.fin_signals(variant='daily')\n",
    "  \"\"\"\n",
    "  \n",
    "  #x2 = hub.growth_signals(variant='daily')\n",
    "  x3 = hub.val_signals()#variant='daily')\n",
    "  print(\"checkpoint 1\")\n",
    "  tickers = client.list_stock_tickers()\n",
    "\n",
    "  print(\"tickers\")\n",
    "  print(tickers)\n",
    "\n",
    "  #x4 = client.get_fundamentals_daily([tickers],startDate='2020-01-01',endDate='2020-12-31')\n",
    "\n",
    "  #x = pd.concat([x1, x3],1)\n",
    "  x = x3\n",
    "  #x.dropna(how='all').head()\n",
    "\n",
    "  print(\"checkpoint 3\")\n",
    "  #df_signals = pd.concat(x, axis=1)\n",
    "\n",
    "  x.dropna(how='all',axis=0,inplace=True)\n",
    "  print(\"x\")\n",
    "  print(x)\n",
    "  print(x.head(0))\n",
    "  #x2 = sf.load_derived(market='us')\n",
    "  y = hub.load_shareprices(variant='daily')\n",
    "  y = y.dropna(how='all').head()\n",
    "  data = pd.concat([x,y],1)\n",
    "  head = data.head(0)\n",
    "\n",
    "  print(\"stage 1 deployed\")\n",
    "\n",
    "  return data\n",
    "  \"\"\"\n",
    "data = dat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.preprocessing import MinMaxScaler\n",
    "from cuml.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperimpute.plugins.imputers import Imputers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "method = \"gain\"\n",
    "\n",
    "plugin = Imputers().get(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = plugin.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# stop training when validation loss does not decrease more than 0.05 (`min_delta`) over\n",
    "# a period of 5 epochs (`patience`)\n",
    "my_stopper = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    min_delta=0.05,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": [0]}#{\"callbacks\": [my_stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "atrain = train.drop(['datetime','target','row_id', 'prediction_unit_id','month', 'day', 'hour', 'dayofweek', 'dayofyear', 'eic_count'],axis=1)\n",
    "btrain = TimeSeries.from_values(atrain,static_covariates=county)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TiDEModel(\n",
    "    input_chunk_length=6,\n",
    "    output_chunk_length=20,\n",
    "    n_epochs=1,\n",
    "    pl_trainer_kwargs=pl_trainer_kwargs,\n",
    ")\n",
    "model.fit(target,past_covariates=btrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[juliapkg] Locating Julia ^1.6.1\n",
      "[juliapkg] Using Julia 1.10.2 at /root/.julia/juliaup/julia-1.10.2+0.x64.linux.gnu/bin/julia\n",
      "[juliapkg] Using Julia project at /root/miniconda3/envs/rapids-23.04/julia_env\n",
      "[juliapkg] Installing packages:\n",
      "           julia> import Pkg\n",
      "           julia> Pkg.add([Pkg.PackageSpec(name=\"PythonCall\", uuid=\"6099a3de-0909-46bc-b1f4-468b9a2dfc0d\")])\n",
      "           julia> Pkg.resolve()\n",
      "           julia> Pkg.precompile()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Updating registry at `~/.julia/registries/General.toml`\n",
      "   Resolving package versions...\n",
      "    Updating `~/miniconda3/envs/rapids-23.04/julia_env/Project.toml`\n",
      "  [6099a3de] + PythonCall v0.9.15\n",
      "    Updating `~/miniconda3/envs/rapids-23.04/julia_env/Manifest.toml`\n",
      "  [992eb4ea] + CondaPkg v0.2.22\n",
      "  [9a962f9c] + DataAPI v1.16.0\n",
      "  [e2d170a0] + DataValueInterfaces v1.0.0\n",
      "  [82899510] + IteratorInterfaceExtensions v1.0.0\n",
      "  [692b3bcd] + JLLWrappers v1.5.0\n",
      "  [0f8b85d8] + JSON3 v1.14.0\n",
      "  [1914dd2f] + MacroTools v0.5.13\n",
      "  [0b3b1443] + MicroMamba v0.1.14\n",
      "  [bac558e1] + OrderedCollections v1.6.3\n",
      "  [69de0a69] + Parsers v2.8.1\n",
      "  [fa939f87] + Pidfile v1.3.0\n",
      "  [aea7be01] + PrecompileTools v1.2.1\n",
      "  [21216c6a] + Preferences v1.4.3\n",
      "  [6099a3de] + PythonCall v0.9.15\n",
      "  [ae029012] + Requires v1.3.0\n",
      "  [6c6a2e73] + Scratch v1.2.1\n",
      "  [856f2bd8] + StructTypes v1.10.0\n",
      "  [3783bdb8] + TableTraits v1.0.1\n",
      "  [bd369af6] + Tables v1.11.1\n",
      "  [e17b2a0c] + UnsafePointers v1.0.0\n",
      "  [f8abcde7] + micromamba_jll v1.4.9+0\n",
      "  [0dad84c5] + ArgTools v1.1.1\n",
      "  [56f22d72] + Artifacts\n",
      "  [2a0f44e3] + Base64\n",
      "  [ade2ca70] + Dates\n",
      "  [f43a241f] + Downloads v1.6.0\n",
      "  [7b1f6079] + FileWatching\n",
      "  [b77e0a4c] + InteractiveUtils\n",
      "  [4af54fe1] + LazyArtifacts\n",
      "  [b27032c2] + LibCURL v0.6.4\n",
      "  [76f85450] + LibGit2\n",
      "  [8f399da3] + Libdl\n",
      "  [37e2e46d] + LinearAlgebra\n",
      "  [56ddb016] + Logging\n",
      "  [d6f4376e] + Markdown\n",
      "  [a63ad114] + Mmap\n",
      "  [ca575930] + NetworkOptions v1.2.0\n",
      "  [44cfe95a] + Pkg v1.10.0\n",
      "  [de0858da] + Printf\n",
      "  [3fa0cd96] + REPL\n",
      "  [9a3f8284] + Random\n",
      "  [ea8e919c] + SHA v0.7.0\n",
      "  [9e88b42a] + Serialization\n",
      "  [6462fe0b] + Sockets\n",
      "  [fa267f1f] + TOML v1.0.3\n",
      "  [a4e569a6] + Tar v1.10.0\n",
      "  [8dfed614] + Test\n",
      "  [cf7118a7] + UUIDs\n",
      "  [4ec0a83e] + Unicode\n",
      "  [e66e0078] + CompilerSupportLibraries_jll v1.1.0+0\n",
      "  [deac9b47] + LibCURL_jll v8.4.0+0\n",
      "  [e37daf67] + LibGit2_jll v1.6.4+0\n",
      "  [29816b5a] + LibSSH2_jll v1.11.0+1\n",
      "  [c8ffd9c3] + MbedTLS_jll v2.28.2+1\n",
      "  [14a3606d] + MozillaCACerts_jll v2023.1.10\n",
      "  [4536629a] + OpenBLAS_jll v0.3.23+4\n",
      "  [83775a58] + Zlib_jll v1.2.13+1\n",
      "  [8e850b90] + libblastrampoline_jll v5.8.0+1\n",
      "  [8e850ede] + nghttp2_jll v1.52.0+1\n",
      "  [3f19e933] + p7zip_jll v17.4.0+2\n",
      "Precompiling project...\n",
      "  ✓ IteratorInterfaceExtensions\n",
      "  ✓ DataValueInterfaces\n",
      "  ✓ Scratch\n",
      "  ✓ DataAPI\n",
      "  ✓ UnsafePointers\n",
      "  ✓ Pidfile\n",
      "  ✓ CompilerSupportLibraries_jll\n",
      "  ✓ Requires\n",
      "  ✓ OrderedCollections\n",
      "  ✓ Preferences\n",
      "  ✓ TableTraits\n",
      "  ✓ StructTypes\n",
      "  ✓ PrecompileTools\n",
      "  ✓ JLLWrappers\n",
      "  ✓ Tables\n",
      "  ✓ micromamba_jll\n",
      "  ✓ MicroMamba\n",
      "  ✓ MacroTools\n",
      "  ✓ Parsers\n",
      "  ✓ JSON3\n",
      "  ✓ CondaPkg\n",
      "  ✓ PythonCall\n",
      "  22 dependencies successfully precompiled in 21 seconds. 3 already precompiled.\n",
      "  No Changes to `~/miniconda3/envs/rapids-23.04/julia_env/Project.toml`\n",
      "  No Changes to `~/miniconda3/envs/rapids-23.04/julia_env/Manifest.toml`\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from juliacall import Main as jl, convert as jlconvert\n",
    "\n",
    "model = jl.Chain(\n",
    "    jl.Dense(1, 10, jl.relu),\n",
    "    jl.Dense(10, 10, jl.relu),\n",
    "    jl.Dense(10, 10, jl.relu),\n",
    "    jl.Dense(10, 1),\n",
    ")\n",
    "loss = jl.seval(\"m -> (x, y) -> Flux.Losses.mse(m(x), y)\")(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "primary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
